{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "from gurobipy import *\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from ucimlrepo import fetch_ucirepo as fetc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Check Data Status (From UCIMLREPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Area               800 non-null    float64\n",
      " 1   Perimeter          800 non-null    float64\n",
      " 2   Major_Axis_Length  800 non-null    float64\n",
      " 3   Minor_Axis_Length  800 non-null    float64\n",
      " 4   Eccentricity       800 non-null    float64\n",
      " 5   Convex_Area        800 non-null    float64\n",
      " 6   Extent             800 non-null    float64\n",
      " 7   target             800 non-null    int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 50.1 KB\n",
      "       Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
      "0  0.507313   0.504348           0.447994           0.650306      0.528006   \n",
      "1  0.503786   0.378801           0.347530           0.688925      0.401748   \n",
      "2  0.551395   0.446065           0.372872           0.747982      0.363165   \n",
      "3  0.574525   0.579105           0.643198           0.557254      0.736598   \n",
      "4  0.291256   0.225480           0.264713           0.407831      0.614529   \n",
      "\n",
      "   Convex_Area    Extent  target  \n",
      "0     0.529585  0.239656       0  \n",
      "1     0.494773  0.393998       1  \n",
      "2     0.551000  0.431947       1  \n",
      "3     0.569167  0.826739       0  \n",
      "4     0.282858  0.195896       1  \n"
     ]
    }
   ],
   "source": [
    "rice = fetc(id=545)\n",
    "X = rice.data.features \n",
    "y = rice.data.targets\n",
    "df = pd.DataFrame(X, columns=rice.data.feature_names).sample(n=800, random_state=42)\n",
    "df['target'] = y\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Change non numeric columns to numeric\n",
    "column_names = [\"Area\", \"Perimeter\", \"Major_Axis_Length\", \"Minor_Axis_Length\",\"Eccentricity\", \"Convex_Area\", \"Extent\", \"target\"]\n",
    "non_numeric_cols = df.drop(['target'],axis=1).select_dtypes(exclude=[np.number]).columns\n",
    "if not non_numeric_cols.empty:\n",
    "    for col in non_numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = StandardScaler().fit_transform(df[[col]])\n",
    "    \n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = MinMaxScaler().fit_transform(df[[col]])\n",
    "\n",
    "#Convert target column to numeric\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['target'])\n",
    "        \n",
    "df.info()\n",
    "#df.isnull().sum()\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Check Data Status (From TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"c:\\\\Users\\\\zhuoq\\\\Downloads\\\\AMS515 Project\\\\Loan Application Classification matrix_train.txt\", delim_whitespace=True).drop(['const'], axis=1)\n",
    "df.rename(columns={'scenario_benchmark': 'target'}, inplace=True)\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "non_numeric_cols = df.drop(['target'],axis=1).select_dtypes(exclude=[np.number]).columns\n",
    "if not non_numeric_cols.empty:\n",
    "    for col in non_numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = StandardScaler().fit_transform(df[[col]])\n",
    "\n",
    "#normalize the data    \n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = MinMaxScaler().fit_transform(df[[col]])\n",
    "\n",
    "#Convert target column to numeric\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['target'])\n",
    "\n",
    "df = df.sample(n=4000, random_state=42)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Class: 2 which are: [0 1]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "print(\"Total number of Class: \" + str(len(np.unique(y))) + \" which are: \" + str(np.unique(y)))\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = pd.DataFrame(x_train, columns=X.columns)\n",
    "df_train['target'] = y_train\n",
    "df_train = df_train.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy Score:  0.89125 Training Set Accuracy Score: 0.8971875\n"
     ]
    }
   ],
   "source": [
    "def clf(x_train, y_train, x_test, y_test,K):\n",
    "    clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=K, random_state=42)\n",
    "    clf_gini.fit(x_train, y_train)\n",
    "    y_pred_gini = clf_gini.predict(x_test)\n",
    "    y_pred_gini_train = clf_gini.predict(x_train)\n",
    "    print('Testing Set Accuracy Score: ', accuracy_score(y_test, y_pred_gini), 'Training Set Accuracy Score:',accuracy_score(y_train, y_pred_gini_train))\n",
    "\n",
    "clf(x_train, y_train, x_test, y_test,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Structure: Will be Used for Warmstart of OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Indices:  [1, 0, 0] Threshold Indices: [0.4952651560306549, 0.5, 0.4496598541736603]\n",
      "4\n",
      "Internal nodes: 3, Total nodes: 7\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=2, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "\"\"\"\n",
    "The following is for warm start in OCT\n",
    "\"\"\"\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "feature_indices = []\n",
    "threshold_indices = []\n",
    "feature_indices_leaf =[]\n",
    "threshold_indices_leaf = []\n",
    "for i in range(len(feature)):\n",
    "    if feature[i] != -2 and feature[i+1] != -2:\n",
    "        feature_indices.append(int(feature[i]))\n",
    "        threshold_indices.append(float(threshold[i]))\n",
    "    elif feature[i] != -2 and feature[i+1] == -2:\n",
    "        feature_indices_leaf.append(int(feature[i]))\n",
    "        threshold_indices_leaf.append(float(threshold[i]))\n",
    "    else:\n",
    "        continue\n",
    "feature_indices.extend(feature_indices_leaf)\n",
    "threshold_indices.extend(threshold_indices_leaf)\n",
    "print(\"Feature Indices: \", feature_indices, \"Threshold Indices:\", threshold_indices)\n",
    "#leaf nodes\n",
    "#branch nodes\n",
    "print(np.sum(clf.tree_.feature == -2))\n",
    "internal_nodes = np.sum(clf.tree_.feature != -2)\n",
    "total_nodes = clf.tree_.node_count\n",
    "print(f\"Internal nodes: {internal_nodes}, Total nodes: {total_nodes}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf nodes: 4, Branch nodes: 3\n"
     ]
    }
   ],
   "source": [
    "total_nodes = clf.tree_.node_count\n",
    "leaf_nodes = round(total_nodes / 2)\n",
    "branch_nodes = total_nodes // 2\n",
    "print(f\"Leaf nodes: {leaf_nodes}, Branch nodes: {branch_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCT Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2643923\n",
      "Academic license - for non-commercial use only - expires 2026-03-28\n"
     ]
    }
   ],
   "source": [
    "m = gp.Model('OCT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraining data (X,Y)=(x_i,y_i), i=1,...,n; x_i in R^p and normalized to [0,1]^p, y_i in {1,...,K}\\n-n = # obervations\\n-p = # features\\n-K = # class label\\n\\n-p(t) = parent nodes of node t\\n-A_L(t) = {left_branch ancestors of t} = {t if tmod2=0 and t/2 recursively gives the set}\\n-A_R(t) = {right_branch ancestors of t} = {t if (t-1)mod2=0 and (t-1)/2 recursively gives the set}\\n\\n\\n-D = max depth\\n-T = 2^(D+1)-1 = max # nodes\\n-TB = branch nodes = left nodes = {1,...,floor(T/2)} applies split is ax<b \\n-TL = leaf = {floor(T/2)+1,...,T} make class prediction\\n-?a_t in R^p\\n-?b_t in R\\n-p = # features\\n\\n-d_t = 1{node t applies a split}\\n-sum a_jt = d_t, j=1,...p, t in TB\\n-0 <= b_t <= d_t, t in TB\\n-a_jt in {0,1}, j=1,...p, t in TB\\n\\n\\n-d_t <= d_p(t), t in TB/{1}\\n\\n-z_it = 1{x_i in node t}\\n-l_t = 1{leaf t contains any point}\\n-z_it <= l_t, t in TB\\n-sum(z_it) >= N_min*l_t for i=1,...,n, t in TB\\n-sum(z_it)=1 for t in TB, i=1,...,n\\n\\n-x_j^i = ith largest value in feature j\\n-epsilon_j = min{x_j^(i+1)-x_j^i, i=1,...,n}\\n-epsilon_max = max{epsilon_j} wrt j\\n-epsilon  = {epsilon_1,...,epsilon_p}\\n-a_m(x_t + epsilon) <= b_m +(1+epsilon_max)(1-z_it), i=1,...,n, for all t in TB, for all m in A_L(t)\\n-a_m*x_i >= b_m - (1-z_it), i=1,...,n, for all t in TB, for all m in A_R(t)\\n\\n-Y_ik = {1 if y_i=k, -1 otherwise}, k=1,...,K, i=1,...n\\nN_kt = 0.5*sum((1+Y_ik)z_it) for i=1,...,n; k=1,...K, t in TL\\nN_t = sum(z_it) for i=1,...,n; t in TL\\nc_t = argmax{N_kt} wrt k\\nc_kt = 1{c_t = k}\\nsum(c_kt) = l_t wrt k\\n\\nL_t = N_t - max{N_kt} wrt k = min{N_t - N_kt} wrt k\\nL_t >= N_t - N_kt - n(1-c_kt), k=1,...K, t in TL\\nL_t <= N_t - N_kt + n*c_kt, k=1,...K, t in TL\\nL_t >= 0\\n\\nL^ = baseline accuracy = #{most popular class}/n\\n\\nobjective: min (1/L^)sum(L_t) for t in TL + alpha*sum(d_t) for t in TB\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "training data (X,Y)=(x_i,y_i), i=1,...,n; x_i in R^p and normalized to [0,1]^p, y_i in {1,...,K}\n",
    "-n = # obervations\n",
    "-p = # features\n",
    "-K = # class label\n",
    "\n",
    "-p(t) = parent nodes of node t\n",
    "-A_L(t) = {left_branch ancestors of t} = {t if tmod2=0 and t/2 recursively gives the set}\n",
    "-A_R(t) = {right_branch ancestors of t} = {t if (t-1)mod2=0 and (t-1)/2 recursively gives the set}\n",
    "\n",
    "\n",
    "-D = max depth\n",
    "-T = 2^(D+1)-1 = max # nodes\n",
    "-TB = branch nodes = left nodes = {1,...,floor(T/2)} applies split is ax<b \n",
    "-TL = leaf = {floor(T/2)+1,...,T} make class prediction\n",
    "-?a_t in R^p\n",
    "-?b_t in R\n",
    "-p = # features\n",
    "\n",
    "-d_t = 1{node t applies a split}\n",
    "-sum a_jt = d_t, j=1,...p, t in TB\n",
    "-0 <= b_t <= d_t, t in TB\n",
    "-a_jt in {0,1}, j=1,...p, t in TB\n",
    "\n",
    "\n",
    "-d_t <= d_p(t), t in TB/{1}\n",
    "\n",
    "-z_it = 1{x_i in node t}\n",
    "-l_t = 1{leaf t contains any point}\n",
    "-z_it <= l_t, t in TB\n",
    "-sum(z_it) >= N_min*l_t for i=1,...,n, t in TB\n",
    "-sum(z_it)=1 for t in TB, i=1,...,n\n",
    "\n",
    "-x_j^i = ith largest value in feature j\n",
    "-epsilon_j = min{x_j^(i+1)-x_j^i, i=1,...,n}\n",
    "-epsilon_max = max{epsilon_j} wrt j\n",
    "-epsilon  = {epsilon_1,...,epsilon_p}\n",
    "-a_m(x_t + epsilon) <= b_m +(1+epsilon_max)(1-z_it), i=1,...,n, for all t in TB, for all m in A_L(t)\n",
    "-a_m*x_i >= b_m - (1-z_it), i=1,...,n, for all t in TB, for all m in A_R(t)\n",
    "\n",
    "-Y_ik = {1 if y_i=k, -1 otherwise}, k=1,...,K, i=1,...n\n",
    "N_kt = 0.5*sum((1+Y_ik)z_it) for i=1,...,n; k=1,...K, t in TL\n",
    "N_t = sum(z_it) for i=1,...,n; t in TL\n",
    "c_t = argmax{N_kt} wrt k\n",
    "c_kt = 1{c_t = k}\n",
    "sum(c_kt) = l_t wrt k\n",
    "\n",
    "L_t = N_t - max{N_kt} wrt k = min{N_t - N_kt} wrt k\n",
    "L_t >= N_t - N_kt - n(1-c_kt), k=1,...K, t in TL\n",
    "L_t <= N_t - N_kt + n*c_kt, k=1,...K, t in TL\n",
    "L_t >= 0\n",
    "\n",
    "L^ = baseline accuracy = #{most popular class}/n\n",
    "\n",
    "objective: min (1/L^)sum(L_t) for t in TL + alpha*sum(d_t) for t in TB\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predetermined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: [0.0013605442176869431, 0.0018939393939392257]\n",
      "epsilon_max: 0.0018939393939392257\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n= df_train.shape[0] # number of observations\n",
    "p = df_train.drop(['target'],axis=1).shape[1] # number of features\n",
    "K = len(np.unique(df_train['target'])) # number of classes\n",
    "D = 2 # max depth\n",
    "T = 2**(D+1)-1 # max number of nodes\n",
    "L_hat = df_train['target'].value_counts().max()/n # baseline accuracy, predicting the most popular class for the dataset\n",
    "N_min = math.floor(n*0.05)\n",
    "X_train = df_train.drop(['target'],axis=1)\n",
    "\n",
    "#Epsilon\n",
    "epsilon=[]\n",
    "for j in range(p):\n",
    "    x_j = df_train.iloc[:,j].tolist()\n",
    "    x_j.sort()  \n",
    "    e=[]\n",
    "    for i in range(n-1):\n",
    "        if x_j[i+1]!=x_j[i]:\n",
    "            e.append(x_j[i+1] - x_j[i])\n",
    "    epsilon.append(min(e))\n",
    "epsilon_max = max(epsilon)\n",
    "\n",
    "print(\"epsilon: \" + str(epsilon))\n",
    "print(\"epsilon_max: \" + str(epsilon_max))\n",
    "\n",
    "#Y Matrix\n",
    "Y = np.zeros([n,K], dtype = int) - 1 # Y_ik\n",
    "Y[df_train.index,  y_train.tolist()] = 1  #based on the sample code, the [x,y] x is the features index, y is the class index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predetermined Sets (Note that index starts from 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch nodes:  [1, 2, 3]\n",
      "Leaf nodes:  [4, 5, 6, 7]\n",
      "left_ancestors: [[], [1], [], [1, 2], [1], [3], []]\n",
      "right_ancestors: [[], [], [1], [], [2], [1], [1, 3]]\n"
     ]
    }
   ],
   "source": [
    "left_ancestors = []\n",
    "right_ancestors = []\n",
    "for t in range(1,T+1):\n",
    "    la_t =[]\n",
    "    ra_t =[]\n",
    "    tau=t\n",
    "    while tau>1:\n",
    "        pt = tau//2\n",
    "        if tau % 2 == 0: #if t is even, then its parent is a left ancestor, else is a right ancestor\n",
    "            la_t.append(pt)\n",
    "        else:\n",
    "            ra_t.append(pt)\n",
    "        tau = pt\n",
    "    la_t.sort() \n",
    "    ra_t.sort()\n",
    "    left_ancestors.append(la_t)\n",
    "    right_ancestors.append(ra_t)\n",
    "\n",
    "TB = list(range(1,math.floor((T+1)/2)))  #Branch nodes\n",
    "TL = list(range(math.floor((T+1)/2),T+1)) #Leaf nodes\n",
    "\n",
    "print(\"Branch nodes: \", TB)\n",
    "print(\"Leaf nodes: \", TL)\n",
    "\n",
    "print(\"left_ancestors: \" + str(left_ancestors))\n",
    "print(\"right_ancestors: \" + str(right_ancestors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m.addVars(p,TB, vtype=GRB.BINARY, name=\"a_t\") #dim |TB|xp\n",
    "b = m.addVars(TB, vtype=GRB.CONTINUOUS, lb = 0, ub = 1, name=\"b_t\") #dim |TB|\n",
    "d = m.addVars(TB, vtype=GRB.BINARY, name=\"d_t\") #dim |TB|\n",
    "z = m.addVars(n, TL, vtype=GRB.BINARY, name=\"z\") #dim nx|TL|\n",
    "l = m.addVars(TL, vtype=GRB.BINARY, name=\"l_t\") #dim |TL|\n",
    "Nk = m.addVars(K, TL, vtype=GRB.INTEGER,name=\"N_kt\") #dim Kx|TL|\n",
    "N = m.addVars(TL, vtype=GRB.INTEGER, name=\"N_t\") #dim |TL|\n",
    "ck = m.addVars(K, TL, vtype=GRB.BINARY, name=\"c_kt\")\n",
    "L = m.addVars(TL, name=\"L_t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm start using the results of CART algorithm\n",
    "for i in TB:\n",
    "    a[feature_indices[i-1], i].start = 1\n",
    "    b[i].start = threshold_indices[i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in TB:\n",
    "    m.addConstr(a.sum(\"*\",t) == d[t], name=\"sum_constraint_of_ajt\") # sum of ajt = dt\n",
    "    m.addConstr(b[t] <= d[t], name=\"bt_constraint_dt\")     # bt <= dt\n",
    "    m.addConstr(d[t] == 1, name=\"dt_constraint_d(t)\")  \n",
    "\n",
    "for t in TB[1:]:\n",
    "    m.addConstr(d[t] <= d[t//2], name=\"dt_constraint_dp(t)\") # dt <= dp(t)    \n",
    "\n",
    "for i in range(n):\n",
    "    m.addConstr(z.sum(i,\"*\") == 1, name=\"sum_of_zi(t)_constraint_1\")  # sum sum of zit = 1\n",
    "    \n",
    "for t in TL:\n",
    "    m.addConstr(z.sum(\"*\",t) >= N_min*l[t], name=\"sum_of_zt_constraint_Nmin_lt\") # sum of zit >= Nmin*lt\n",
    "    for i in range(n):\n",
    "        m.addConstr(z[i, t] <= l[t]) # zit <= lt\n",
    "    \n",
    "    for k in range(K):\n",
    "        m.addConstr(Nk[k,t] == 1/2 * gp.quicksum(z[i,t] * (Y[i,k] + 1) for i in range(n))) #Nkt = 1/2(sum of (1+Yik)*zit #may need to be corrected\n",
    "\n",
    "    m.addConstr(N[t] == z.sum(\"*\",t))  # Nt = sum of zit\n",
    "\n",
    "    m.addConstr(l[t] == ck.sum(\"*\",t)) # sum of ckt = lt\n",
    "    \n",
    "    m.addConstr(l[t] == 1, name=\"dt_constraint_l(t)\")\n",
    "\n",
    "#m.addConstr(N.sum(\"*\") == n, name=\"sum_of_N(t)_constraint\") # sum of zit <= n*lt\n",
    "    \n",
    "for t in TL:\n",
    "    l_ancestors = left_ancestors[t - 1]  # cache the list\n",
    "    if l_ancestors:\n",
    "        for la in l_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X_train.iloc[i]  # cache row once\n",
    "                m.addConstr(gp.quicksum(a[j, la] * (xi[j] + epsilon[j]) for j in range(p)) <= b[la] + (1 + epsilon_max) * (1 - z[i, t]),\n",
    "                    name=f\"split_l_{la}_{i}_{t}\"\n",
    "                )\n",
    "                \n",
    "    r_ancestors = right_ancestors[t - 1]\n",
    "    if r_ancestors:\n",
    "        for r in r_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X_train.iloc[i]  # cache the row once\n",
    "                m.addConstr(\n",
    "                    gp.quicksum(a[j, r] * xi[j] for j in range(p)) >= b[r] - (1 - z[i, t]),\n",
    "                    name=f\"split_r_{r}_{i}_{t}\"\n",
    "                )\n",
    "        \n",
    "for t in TL:\n",
    "    m.addConstr(L[t] >= 0, name=\"Lt_constraint3\") #Lt ≥ 0\n",
    "    for k in range(K):\n",
    "        m.addConstr(L[t] >= N[t] - Nk[k,t] - n*(1-ck[k,t]), name=\"Lt_constraint1\") #Lt ≤ Nt − Nkt + n(1-ckt) \n",
    "        m.addConstr(L[t] <= N[t] - Nk[k,t] + n*ck[k,t], name=\"Lt_constraint2\")  #Lt ≤ Nt − Nkt + n*ckt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update()\n",
    "m.setObjective(L.sum('*') / L_hat + 0.5*gp.quicksum(d[t] for t in TB), GRB.MINIMIZE) #minimize L + alpha*sum(d_t) for t in TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 3000\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) Ultra 9 185H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 22 logical processors, using up to 22 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  3000\n",
      "\n",
      "Optimize a model with 145765 rows, 44920 columns and 627546 nonzeros\n",
      "Model fingerprint: 0x268815b9\n",
      "Variable types: 21 continuous, 44899 integer (44863 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-03, 4e+03]\n",
      "  Objective range  [5e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+03]\n",
      "\n",
      "Warning: Completing partial solution with 44890 unfixed non-continuous variables out of 44899\n",
      "User MIP start did not produce a new incumbent solution\n",
      "MIP start from previous solve produced solution with objective 426.757 (2.61s)\n",
      "MIP start from previous solve produced solution with objective 424.407 (3.02s)\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 6s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 10s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 15s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 21s\n",
      "MIP start from previous solve produced solution with objective 410.311 (23.40s)\n",
      "MIP start from previous solve produced solution with objective 386.816 (23.46s)\n",
      "MIP start from previous solve produced solution with objective 383.291 (23.71s)\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 25s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 31s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 36s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 40s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 45s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 50s\n",
      "Processing MIP start from previous solve: 0 nodes explored in subMIP, total elapsed time 55s\n",
      "Processing MIP start from previous solve: 2 nodes explored in subMIP, total elapsed time 60s\n",
      "Processing MIP start from previous solve: 6 nodes explored in subMIP, total elapsed time 65s\n",
      "Processing MIP start from previous solve: 29 nodes explored in subMIP, total elapsed time 70s\n",
      "Processing MIP start from previous solve: 45 nodes explored in subMIP, total elapsed time 75s\n",
      "Processing MIP start from previous solve: 88 nodes explored in subMIP, total elapsed time 80s\n",
      "Processing MIP start from previous solve: 127 nodes explored in subMIP, total elapsed time 85s\n",
      "Processing MIP start from previous solve: 234 nodes explored in subMIP, total elapsed time 90s\n",
      "Processing MIP start from previous solve: 397 nodes explored in subMIP, total elapsed time 95s\n",
      "Processing MIP start from previous solve: 420 nodes explored in subMIP, total elapsed time 100s\n",
      "MIP start from previous solve produced solution with objective 375.068 (100.84s)\n",
      "MIP start from previous solve produced solution with objective 373.894 (100.85s)\n",
      "Loaded MIP start from previous solve with objective 373.894\n",
      "Processed MIP start in 103.02 seconds (152.12 work units)\n",
      "\n",
      "Presolve removed 80917 rows and 16076 columns (presolve time = 13s)...\n",
      "Presolve removed 80917 rows and 16076 columns\n",
      "Presolve time: 12.65s\n",
      "Presolved: 64848 rows, 28844 columns, 230536 nonzeros\n",
      "Variable types: 6 continuous, 28838 integer (28814 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex (primal and dual model)\n",
      "Showing primal log only...\n",
      "\n",
      "Root relaxation presolved: 64848 rows, 28844 columns, 230536 nonzeros\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.5000000e+00   7.502907e+03   2.201112e+10    117s\n",
      "   15302    1.5000000e+00   0.000000e+00   0.000000e+00    117s\n",
      "Concurrent spin time: 0.10s (can be avoided by choosing Method=3)\n",
      "\n",
      "Solved with primal simplex\n",
      "\n",
      "Root relaxation: objective 1.500000e+00, 15302 iterations, 0.45 seconds (0.38 work units)\n",
      "Total elapsed time = 122.26s (DegenMoves)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.50000    0  108  373.89354    1.50000   100%     -  125s\n",
      "     0     0    1.50000    0  752  373.89354    1.50000   100%     -  128s\n",
      "     0     0    1.50000    0 1210  373.89354    1.50000   100%     -  130s\n",
      "     0     0    1.50000    0  442  373.89354    1.50000   100%     -  142s\n",
      "     0     0    1.50000    0 1370  373.89354    1.50000   100%     -  143s\n",
      "     0     0    1.50000    0 1837  373.89354    1.50000   100%     -  145s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\iostream.py:655\u001b[39m, in \u001b[36mOutStream.write\u001b[39m\u001b[34m(self, string)\u001b[39m\n\u001b[32m    647\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    649\u001b[39m             \u001b[38;5;28mself\u001b[39m.session.send(\n\u001b[32m    650\u001b[39m                 \u001b[38;5;28mself\u001b[39m.pub_thread,\n\u001b[32m    651\u001b[39m                 msg,\n\u001b[32m    652\u001b[39m                 ident=\u001b[38;5;28mself\u001b[39m.topic,\n\u001b[32m    653\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, string: \u001b[38;5;28mstr\u001b[39m) -> Optional[\u001b[38;5;28mint\u001b[39m]:  \u001b[38;5;66;03m# type:ignore[override]\u001b[39;00m\n\u001b[32m    656\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write to current stream after encoding if necessary\u001b[39;00m\n\u001b[32m    657\u001b[39m \n\u001b[32m    658\u001b[39m \u001b[33;03m    Returns\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    662\u001b[39m \n\u001b[32m    663\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    664\u001b[39m     parent = \u001b[38;5;28mself\u001b[39m.parent_header\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gurobipy._core.logcallbackstub'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\zhuoq\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\iostream.py\", line 655, in write\n",
      "    def write(self, string: str) -> Optional[int]:  # type:ignore[override]\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     0    1.50000    0  648  373.89354    1.50000   100%     -  155s\n",
      "     0     0    1.50000    0  914  373.89354    1.50000   100%     -  157s\n",
      "     0     0    1.50000    0  643  373.89354    1.50000   100%     -  157s\n",
      "     0     0    1.50000    0  448  373.89354    1.50000   100%     -  164s\n",
      "     0     0    1.50000    0  372  373.89354    1.50000   100%     -  167s\n"
     ]
    }
   ],
   "source": [
    "m.Params.timelimit = 3000\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Tree Structure (OCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTree Structure: \\n\\nVariables a, b, z, N_k and c=argmax{N_kt} are the decisive variables for the tree structure. \\n\\nTake a point x_i, if <a_1,x_i> <= b_1, then x_i is down to node 2, otherwise down to node 3;\\nsuppose x_i gets to node 2, then if <a_2,x_i> <= b_2, then x_i will be in node 4, otherwise node 5.\\n\\nSuch process continues until x_i reaches a leaf node.\\n\\nFor each leaf node t, we then count the number of points in each class k, which is N_kt.\\n\\nmax{N_kt} represents the most popular class, which is c_t, in leaf node t, but not every point in \\nsuch leaf is of class c_t.\\n\\nIf L_t = 0, then every point in leaf node t is indeed of class c_t, and the tree is pure. \\n\\nSo L_t is the number of misclassified points in leaf node t.\\n\\nSince every point can only be in one of the leaf nodes, the sum of L_t is the total number of\\nmisclassified points in the tree.\\n\\nFor a testing set, we create a tree with the splitting criterion based on a and b; then N_kt and L_t are what\\nneed to be calculated to access the accuracy of the tree on the testing set. The number of splits in each level\\nof the testing tree is the number of observations times the number of branch nodes. \\n\\nThe problem is then how to perform the splits efficiently? \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tree Structure: \n",
    "\n",
    "Variables a, b, z, N_k and c=argmax{N_kt} are the decisive variables for the tree structure. \n",
    "\n",
    "Take a point x_i, if <a_1,x_i> <= b_1, then x_i is down to node 2, otherwise down to node 3;\n",
    "suppose x_i gets to node 2, then if <a_2,x_i> <= b_2, then x_i will be in node 4, otherwise node 5.\n",
    "\n",
    "Such process continues until x_i reaches a leaf node.\n",
    "\n",
    "For each leaf node t, we then count the number of points in each class k, which is N_kt.\n",
    "\n",
    "max{N_kt} represents the most popular class, which is c_t, in leaf node t, but not every point in \n",
    "such leaf is of class c_t.\n",
    "\n",
    "If L_t = 0, then every point in leaf node t is indeed of class c_t, and the tree is pure. \n",
    "\n",
    "So L_t is the number of misclassified points in leaf node t.\n",
    "\n",
    "Since every point can only be in one of the leaf nodes, the sum of L_t is the total number of\n",
    "misclassified points in the tree.\n",
    "\n",
    "For a testing set, we create a tree with the splitting criterion based on a and b; then N_kt and L_t are what\n",
    "need to be calculated to access the accuracy of the tree on the testing set. The number of splits in each level\n",
    "of the testing tree is the number of observations times the number of branch nodes. \n",
    "\n",
    "The problem is then how to perform the splits efficiently? \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Structure Alternative 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_matrix(a): [[0. 1. 0.]\n",
      " [1. 0. 1.]]\n",
      "threshold_oct(b): [0.34090909 0.46530612 0.36174242]\n",
      "points_leaf(N): [ 256.  208. 2366. 1170.]\n",
      "4000\n",
      "4000.0\n"
     ]
    }
   ],
   "source": [
    "a_matrix = np.zeros((p, len(TB))) #a[i,t]\n",
    "threshold_oct = np.zeros(len(TB)) #b[i]\n",
    "points_leaf = np.zeros(len(TL)) #N[i]\n",
    "\n",
    "for i in TB:\n",
    "    threshold_oct[i-1] = b[i].X #threshold \n",
    "    \n",
    "for i in range(p):\n",
    "    for t_idx, t in enumerate(TB):  # convert TB to indexable order\n",
    "        a_matrix[i, t_idx] = a[i, t].X\n",
    "        \n",
    "for i in range(len(TL)):\n",
    "    points_leaf[i-1] = N[i+2**D].X #N[i]\n",
    "\n",
    "print(\"a_matrix(a): \" + str(a_matrix))\n",
    "print(\"threshold_oct(b): \" + str(threshold_oct))\n",
    "print(\"points_leaf(N): \" + str(points_leaf))\n",
    "print(x_train.shape[0])\n",
    "print(sum(points_leaf)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of misclassified points: 571\n",
      "Train Set Accuracy: 0.85725\n",
      "Train Set Accuracy: 0.85725\n",
      "Test Set Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "Leaf_classes = [[] for _ in range(2**D)]\n",
    "for i in range(x_train.shape[0]):\n",
    "    j =1\n",
    "    while j < 2**D:\n",
    "        x_i = x_train.iloc[i].to_numpy()\n",
    "        if np.dot(a_matrix[:, j-1],x_i)<threshold_oct[j-1]:\n",
    "            j = 2*j\n",
    "        else:\n",
    "            j = 2*j + 1\n",
    "    Leaf_classes[j-2**D].append(y_train.tolist()[i])\n",
    "\n",
    "nonaccurate = 0\n",
    "for leaf in Leaf_classes:\n",
    "    if leaf:\n",
    "        predicted_class = max(set(leaf), key=leaf.count)\n",
    "        misclassified = len(leaf) - leaf.count(predicted_class)\n",
    "        nonaccurate += misclassified\n",
    "\n",
    "print(\"Total number of misclassified points: \" + str(nonaccurate))\n",
    "print(\"Train Set Accuracy: \" + str((x_train.shape[0] - nonaccurate) / x_train.shape[0]))\n",
    "\n",
    "def oct_accuracy(x,y,a,b,D):\n",
    "    Leaf_classes = [[] for _ in range(2**D)]\n",
    "    for i in range(x.shape[0]):\n",
    "        j =1\n",
    "        while j < 2**D:\n",
    "            x_i = x.iloc[i].to_numpy()\n",
    "            if np.dot(a[:, j-1],x_i)<b[j-1]:\n",
    "                j = 2*j\n",
    "            else:\n",
    "                j = 2*j + 1\n",
    "        Leaf_classes[j-2**D].append(y.tolist()[i])\n",
    "    \n",
    "    nonaccurate = 0\n",
    "    for leaf in Leaf_classes:\n",
    "        if leaf:\n",
    "            predicted_class = max(set(leaf), key=leaf.count)\n",
    "            misclassified = len(leaf) - leaf.count(predicted_class)\n",
    "            nonaccurate += misclassified\n",
    "\n",
    "    return (x.shape[0] - nonaccurate) / x.shape[0]\n",
    "\n",
    "print(\"Train Set Accuracy: \" + str(oct_accuracy(x_train,y_train,a_matrix,threshold_oct,D)))\n",
    "print(\"Test Set Accuracy: \" + str(oct_accuracy(x_test,y_test,a_matrix,threshold_oct,D)))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of misclassified points: 145\n",
      "Test Set Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Leaf_classes = [[] for _ in range(2**D)]\n",
    "for i in range(x_test.shape[0]):\n",
    "    j =1\n",
    "    while j < 2**D:\n",
    "        x_i = x_test.iloc[i].to_numpy()\n",
    "        if np.dot(a_matrix[:, j-1],x_i)<threshold_oct[j-1]:\n",
    "            j = 2*j\n",
    "        else:\n",
    "            j = 2*j + 1\n",
    "    Leaf_classes[j-2**D].append(y_test.tolist()[i])\n",
    "\n",
    "nonaccurate = 0\n",
    "for leaf in Leaf_classes:\n",
    "    predicted_class = max(set(leaf), key=leaf.count)\n",
    "    misclassified = len(leaf) - leaf.count(predicted_class)\n",
    "    nonaccurate += misclassified\n",
    "\n",
    "print(\"Total number of misclassified points: \" + str(nonaccurate))\n",
    "print(\"Test Set Accuracy: \" + str((x_test.shape[0] - nonaccurate) / x_test.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Structure Alternative 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_matrix(a): [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "threshold_oct(b): [0.67305103 0.58484714 0.43549974]\n",
      "split_position(d): [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a_matrix = np.zeros((p, len(TB))) #a[i,t]\n",
    "threshold_oct = np.zeros(len(TB)) #b[i]\n",
    "split_position = np.zeros(len(TB)) #d[i]\n",
    "\n",
    "for i in TB:\n",
    "    split_position[i-1] = d[i].X #split or not\n",
    "\n",
    "for i in TB:\n",
    "    threshold_oct[i-1] = b[i].X #threshold \n",
    "    \n",
    "for i in range(p):\n",
    "    for t_idx, t in enumerate(TB):  # convert TB to indexable order\n",
    "        a_matrix[i, t_idx] = a[i, t].X\n",
    "\n",
    "print(\"a_matrix(a): \" + str(a_matrix))\n",
    "print(\"threshold_oct(b): \" + str(threshold_oct))\n",
    "print(\"split_position(d): \" + str(split_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Major_Axis_Length</th>\n",
       "      <th>Minor_Axis_Length</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Convex_Area</th>\n",
       "      <th>Extent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.746643</td>\n",
       "      <td>0.724797</td>\n",
       "      <td>0.745690</td>\n",
       "      <td>0.697520</td>\n",
       "      <td>0.674321</td>\n",
       "      <td>0.742259</td>\n",
       "      <td>0.829650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.291516</td>\n",
       "      <td>0.230560</td>\n",
       "      <td>0.242685</td>\n",
       "      <td>0.421303</td>\n",
       "      <td>0.575092</td>\n",
       "      <td>0.287238</td>\n",
       "      <td>0.332955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.302174</td>\n",
       "      <td>0.257664</td>\n",
       "      <td>0.249048</td>\n",
       "      <td>0.431348</td>\n",
       "      <td>0.570109</td>\n",
       "      <td>0.304707</td>\n",
       "      <td>0.249723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.549670</td>\n",
       "      <td>0.418815</td>\n",
       "      <td>0.286837</td>\n",
       "      <td>0.806927</td>\n",
       "      <td>0.186790</td>\n",
       "      <td>0.540795</td>\n",
       "      <td>0.411516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.640695</td>\n",
       "      <td>0.643961</td>\n",
       "      <td>0.557220</td>\n",
       "      <td>0.732178</td>\n",
       "      <td>0.521176</td>\n",
       "      <td>0.643096</td>\n",
       "      <td>0.631189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.371456</td>\n",
       "      <td>0.406843</td>\n",
       "      <td>0.443293</td>\n",
       "      <td>0.394480</td>\n",
       "      <td>0.737510</td>\n",
       "      <td>0.374686</td>\n",
       "      <td>0.267356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.370923</td>\n",
       "      <td>0.319834</td>\n",
       "      <td>0.264266</td>\n",
       "      <td>0.542346</td>\n",
       "      <td>0.468112</td>\n",
       "      <td>0.373954</td>\n",
       "      <td>0.679757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.541356</td>\n",
       "      <td>0.459264</td>\n",
       "      <td>0.363284</td>\n",
       "      <td>0.724679</td>\n",
       "      <td>0.363708</td>\n",
       "      <td>0.536820</td>\n",
       "      <td>0.518902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.470049</td>\n",
       "      <td>0.465351</td>\n",
       "      <td>0.394775</td>\n",
       "      <td>0.600983</td>\n",
       "      <td>0.519104</td>\n",
       "      <td>0.486088</td>\n",
       "      <td>0.313494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0.726604</td>\n",
       "      <td>0.750175</td>\n",
       "      <td>0.779942</td>\n",
       "      <td>0.650793</td>\n",
       "      <td>0.728029</td>\n",
       "      <td>0.718933</td>\n",
       "      <td>0.351742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
       "361  0.746643   0.724797           0.745690           0.697520      0.674321   \n",
       "73   0.291516   0.230560           0.242685           0.421303      0.575092   \n",
       "374  0.302174   0.257664           0.249048           0.431348      0.570109   \n",
       "155  0.549670   0.418815           0.286837           0.806927      0.186790   \n",
       "104  0.640695   0.643961           0.557220           0.732178      0.521176   \n",
       "..        ...        ...                ...                ...           ...   \n",
       "266  0.371456   0.406843           0.443293           0.394480      0.737510   \n",
       "23   0.370923   0.319834           0.264266           0.542346      0.468112   \n",
       "222  0.541356   0.459264           0.363284           0.724679      0.363708   \n",
       "261  0.470049   0.465351           0.394775           0.600983      0.519104   \n",
       "426  0.726604   0.750175           0.779942           0.650793      0.728029   \n",
       "\n",
       "     Convex_Area    Extent  \n",
       "361     0.742259  0.829650  \n",
       "73      0.287238  0.332955  \n",
       "374     0.304707  0.249723  \n",
       "155     0.540795  0.411516  \n",
       "104     0.643096  0.631189  \n",
       "..           ...       ...  \n",
       "266     0.374686  0.267356  \n",
       "23      0.373954  0.679757  \n",
       "222     0.536820  0.518902  \n",
       "261     0.486088  0.313494  \n",
       "426     0.718933  0.351742  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert x_test to array\n",
    "X_test = x_test.astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define node\n",
    "class TreeNode:\n",
    "    def __init__(self, node_id, a=None, b=None, is_leaf=False):\n",
    "        self.node_id = node_id\n",
    "        self.a = a  \n",
    "        self.b = b\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.is_leaf = is_leaf \n",
    "#build the tree\n",
    "def build_tree_from_solution(TB, a_matrix, threshold_oct, split_position):\n",
    "    nodes = {}\n",
    "    #set up nodes \n",
    "    for t_idx, t in enumerate(TB):\n",
    "        is_split = split_position[t_idx] > 0.5  #d[i]=1 > 0.5 if d[i]=0 < 0.5 so we take 0.5 as a measure value\n",
    "        a_vec = a_matrix[:, t_idx]   #ex. a1 = [-0. -0. -0. -0. -0. -0. -0.]\n",
    "        b_val = threshold_oct[t_idx] #ex. b1 =0.42257857\n",
    "        node = TreeNode(node_id=t, a=a_vec, b=b_val, is_leaf=not is_split)\n",
    "        nodes[t] = node\n",
    "    #connect nodes\n",
    "    for t in TB:\n",
    "        if split_position[TB.index(t)] > 0.5:\n",
    "            nodes[t].left = nodes.get(2 * t, TreeNode(node_id=2*t, is_leaf=True))  \n",
    "            nodes[t].right = nodes.get(2 * t + 1, TreeNode(node_id=2*t+1, is_leaf=True))\n",
    "            nodes[2 * t] = nodes[t].left \n",
    "            nodes[2 * t + 1] = nodes[t].right\n",
    "\n",
    "    return nodes[1]     #back to top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root node ID: 1\n"
     ]
    }
   ],
   "source": [
    "root = build_tree_from_solution(TB, a_matrix, threshold_oct, split_position)\n",
    "print(\"Root node ID:\", root.node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_node(x_i, node):\n",
    "    while not node.is_leaf:              #if it does not reach to leaf node, will be assigned to the next node until leaf node\n",
    "        if np.dot(node.a, x_i) <= node.b:  # <a,x_i>   <= b\n",
    "            node = node.left\n",
    "        else:\n",
    "            node = node.right            # <a,x_i>   > b\n",
    "    return node.node_id                  #return which leaf node the x_i belongs to \n",
    "\n",
    "def assign_toleaf(X_data, root):\n",
    "    leaf_assignments = {}\n",
    "    for i, x_i in enumerate(X_data):\n",
    "        leaf_id = predict_node(x_i, root)\n",
    "        if leaf_id not in leaf_assignments:\n",
    "            leaf_assignments[leaf_id] = []\n",
    "        leaf_assignments[leaf_id].append(i)\n",
    "    return leaf_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: [0, 10, 13, 18, 21, 24, 27, 28, 37, 43, 48, 51, 53, 55, 60, 64, 70, 71, 73, 86, 88, 99, 109, 115, 117, 121, 122, 128, 139, 149], 4: [1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 17, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 45, 46, 49, 54, 56, 57, 59, 61, 62, 63, 66, 67, 68, 72, 74, 75, 78, 81, 82, 83, 85, 87, 89, 90, 93, 94, 95, 96, 97, 98, 101, 103, 105, 106, 108, 110, 112, 113, 114, 116, 118, 119, 123, 124, 126, 127, 129, 130, 131, 133, 134, 138, 140, 141, 142, 143, 144, 146, 147, 148], 5: [4, 12, 15, 16, 20, 26, 29, 38, 42, 44, 47, 50, 58, 65, 69, 76, 77, 80, 84, 91, 92, 100, 102, 104, 107, 111, 120, 125, 132, 135, 136, 137], 6: [19, 52, 79, 145]}\n"
     ]
    }
   ],
   "source": [
    "leaf_assignments = assign_toleaf(X_test, root)\n",
    "print(leaf_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "from collections import defaultdict\n",
    "def accuracy(leaf_assignments, Y_data):\n",
    "    Lt = 0\n",
    "    Nt = len(Y_data) #number of points in the nodes (total points)\n",
    "    for leaf_id, x_i in leaf_assignments.items():  #leaf node 10:[1,2,3], 10 is leaf node_id, x_i = {1,2,3}\n",
    "        N_kt = defaultdict(int) \n",
    "        for i in x_i:\n",
    "            N_kt[Y_data.iloc[i]] += 1 #count the number of points in each class\n",
    "        L_t = len(x_i) - max(N_kt.values()) #missclasscifaction: Lt = Nt - max{Nkt}\n",
    "        Lt += L_t\n",
    "        print(f\"Leaf {leaf_id}: class counts = {dict(N_kt)}, misclassified = {L_t}\")\n",
    "\n",
    "    accuracy = (Nt - Lt) / Nt  \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf 7: class counts = {np.int64(0): 30}, misclassified = 0\n",
      "Leaf 4: class counts = {np.int64(1): 78, np.int64(0): 6}, misclassified = 6\n",
      "Leaf 5: class counts = {np.int64(0): 31, np.int64(1): 1}, misclassified = 1\n",
      "Leaf 6: class counts = {np.int64(0): 2, np.int64(1): 2}, misclassified = 2\n",
      "Accuracy Result(OCT): 0.94\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy(leaf_assignments, y_test)\n",
    "print(\"Accuracy Result(OCT): \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCT-H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_h = gp.Model('OCT-H')\n",
    "mu = 0.005  #Base on the paper mu is a sufficiently small constant\n",
    "alpha = 0.5\n",
    "#M = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables: Introduce s and a_hat as New Variables for OCT-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m_h.addVars(p,TB, vtype=GRB.BINARY, name=\"a_t\") #dim px|TB|  ???? 0/1 or -1/1\n",
    "a_hat = m_h.addVars(p, TB, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=\"a_hat\") #dim px|TB|\n",
    "b = m_h.addVars(TB, vtype=GRB.CONTINUOUS, lb = 0, ub = 1, name=\"b_t\") #dim |TB|\n",
    "d = m_h.addVars(TB, vtype=GRB.BINARY, name=\"d_t\") #dim |TB|\n",
    "s = m_h.addVars(p,TB, vtype=GRB.BINARY, name=\"s\") #dim px|TB|\n",
    "z = m_h.addVars(n, TL, vtype=GRB.BINARY, name=\"z\") #dim nx|TL|\n",
    "l = m_h.addVars(TL, vtype=GRB.BINARY, name=\"l_t\") #dim |TL|\n",
    "Nk = m_h.addVars(K, TL, vtype=GRB.INTEGER,name=\"N_kt\") #dim Kx|TL|\n",
    "N = m_h.addVars(TL, vtype=GRB.INTEGER, name=\"N_t\") #dim |TL|\n",
    "ck = m_h.addVars(K, TL, vtype=GRB.BINARY, name=\"c_kt\")\n",
    "L = m_h.addVars(TL, name=\"L_t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm start using the results of CART algorithm\n",
    "for i in TB:\n",
    "    a[feature_indices[i-1], i].start = 1\n",
    "    b[i].start = threshold_indices[i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Constraints (OCT-H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in TB:\n",
    "    m_h.addConstr(d[t] == 1, name=\"dt_constraint_d(t)\") \n",
    "    m_h.addConstr(b[t] <= d[t], name=\"bt_constraint1_dt\")     # bt <= dt\n",
    "    m_h.addConstr(-d[t] <= b[t], name=\"bt_constraint2_dt\")    #-dt <= bt\n",
    "    \n",
    "    m_h.addConstr(s.sum(\"*\",t) >= d[t], name=\"sum_constraint_of_sjt\")  #sum of sjt >= dt\n",
    "    for i in range(p):\n",
    "        m_h.addConstr(s[i,t] <= d[t], name=\"s_constraint1_dt\")     # sjt <= dt\n",
    "        m_h.addConstr(-s[i,t] <= a[i,t], name=\"a_constraint1_-st\")  # -sjt <= ajt\n",
    "        m_h.addConstr(a[i,t] <= s[i,t], name=\"a_constraint2_st\")   # ajt <= sjt  \n",
    "\n",
    "    m_h.addConstr(a_hat.sum(\"*\",t) <= d[t], name=\"sum_constraint_of_a_hat\") #sum of a_hat_jt >= dt\n",
    "    for i in range(p):\n",
    "        m_h.addConstr(a_hat[i,t] >= -a[i,t], name=\"a_hat_constraint_-a\") #a_hat >= -ajt \n",
    "        m_h.addConstr(a_hat[i,t] >= a[i,t], name=\"a_hat_constraint_a\")   #a_hat >= ajt  \n",
    "\n",
    "for t in TB[1:]:\n",
    "    m_h.addConstr(d[t] <= d[t//2], name=\"dt_constraint_dp(t)\") # dt <= dp(t)   \n",
    "\n",
    "for i in range(n):\n",
    "    m_h.addConstr(z.sum(i,\"*\") == 1, name=\"sum_of_zi(t)_constraint_1\")  # sum sum of zit = 1\n",
    "    \n",
    "for t in TL:\n",
    "    m_h.addConstr(z.sum(\"*\",t) >= N_min*l[t], name=\"sum_of_zt_constraint_Nmin_lt\") # sum of zit >= Nmin*lt\n",
    "    \n",
    "    for i in range(n):\n",
    "        m_h.addConstr(z[i, t] <= l[t]) # zit <= lt\n",
    "  \n",
    "    for k in range(K):\n",
    "        m_h.addConstr(Nk[k,t] == 1/2 * gp.quicksum(z[i,t] * (Y[i,k] + 1) for i in range(n))) #Nkt = 1/2(sum of (1+Yik)*zit #may need to be corrected\n",
    "\n",
    "    m_h.addConstr(N[t] == z.sum(\"*\",t))  # Nt = sum of zit\n",
    "    m_h.addConstr(l[t] == ck.sum(\"*\",t)) # sum of ckt = lt\n",
    "    m_h.addConstr(l[t] == 1, name=\"dt_constraint_l(t)\")\n",
    " \n",
    "for t in TL:\n",
    "    l_ancestors = left_ancestors[t - 1]  # cache the list\n",
    "    if l_ancestors:\n",
    "        for la in l_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X.iloc[i]  # cache row once\n",
    "                m_h.addConstr(gp.quicksum(a[j,la] * xi[j] for j in range(p)) + mu <= b[la] + (2 + mu) * (1-z[i, t]),\n",
    "                    name=f\"split_l_{la}_{i}_{t}\"\n",
    "                )\n",
    "                \n",
    "    r_ancestors = right_ancestors[t - 1]\n",
    "    if r_ancestors:\n",
    "        for ra in r_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X.iloc[i]  # cache the row once\n",
    "                m_h.addConstr(\n",
    "                    gp.quicksum(a[j, ra]*xi[j] for j in range(p)) >= b[ra]-2*(1-z[i, t]),\n",
    "                    name=f\"split_r_{ra}_{i}_{t}\"\n",
    "                )\n",
    "         \n",
    "for t in TL:\n",
    "    m_h.addConstr(L[t] >= 0, name=\"Lt_constraint3\") #Lt ≥ 0\n",
    "    for k in range(K):\n",
    "        m_h.addConstr(L[t] >= N[t] - Nk[k,t] - n*(1-ck[k,t]), name=\"Lt_constraint1\") #Lt ≤ Nt − Nkt + n(1-ckt) \n",
    "        m_h.addConstr(L[t] <= N[t] - Nk[k,t] + n*ck[k,t], name=\"Lt_constraint2\")  #Lt ≤ Nt − Nkt + n*ckt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective OCT-H and Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 600\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) Ultra 9 185H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 22 logical processors, using up to 22 threads\n",
      "\n",
      "Optimize a model with 4370 rows, 1497 columns and 32561 nonzeros\n",
      "Model fingerprint: 0x4585df75\n",
      "Variable types: 28 continuous, 1469 integer (1457 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-02, 4e+02]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+02]\n",
      "\n",
      "Warning: Completing partial solution with 1466 unfixed non-continuous variables out of 1469\n",
      "User MIP start produced solution with objective 27.2895 (0.02s)\n",
      "User MIP start produced solution with objective 25.4474 (0.02s)\n",
      "Loaded user MIP start with objective 25.4474\n",
      "\n",
      "Presolve removed 1517 rows and 36 columns\n",
      "Presolve time: 0.04s\n",
      "Presolved: 2853 rows, 1461 columns, 26728 nonzeros\n",
      "Variable types: 3 continuous, 1458 integer (1446 binary)\n",
      "\n",
      "Root relaxation: objective 1.500000e+00, 137 iterations, 0.01 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       1.5000000    1.50000  0.00%     -    0s\n",
      "     0     0    1.50000    0   22    1.50000    1.50000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (826 simplex iterations) in 0.13 seconds (0.13 work units)\n",
      "Thread count was 22 (of 22 available processors)\n",
      "\n",
      "Solution count 3: 1.5 25.4474 27.2895 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.500000000000e+00, best bound 1.500000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "m_h.update()\n",
    "m_h.setObjective(L.sum('*') / L_hat + alpha*gp.quicksum(gp.quicksum(s[i,t] for i in range(p)) for t in TB), GRB.MINIMIZE) #minimize m_h.setObjective(gp.quicksum(L[t]/L_hat for t in TL) + alpha*gp.quicksum(gp.quicksum(s[i,t] for i in range(p)) for t in TB), GRB.MINIMIZE) L + alpha*sum(sum(sjt)) for j in p, t in TB\n",
    "m.Params.timelimit = 600\n",
    "m_h.optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
