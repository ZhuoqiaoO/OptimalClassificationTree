{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "from gurobipy import *\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from ucimlrepo import fetch_ucirepo as fetc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data and Check Data Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3810 entries, 0 to 3809\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Area               3810 non-null   float64\n",
      " 1   Perimeter          3810 non-null   float64\n",
      " 2   Major_Axis_Length  3810 non-null   float64\n",
      " 3   Minor_Axis_Length  3810 non-null   float64\n",
      " 4   Eccentricity       3810 non-null   float64\n",
      " 5   Convex_Area        3810 non-null   float64\n",
      " 6   Extent             3810 non-null   float64\n",
      " 7   target             3810 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 238.3 KB\n",
      "       Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
      "0  0.675937   0.879232           0.901216           0.532417      0.888011   \n",
      "1  0.625330   0.714095           0.648087           0.670663      0.691980   \n",
      "2  0.623394   0.750066           0.734349           0.588124      0.789846   \n",
      "3  0.495071   0.524136           0.512800           0.581461      0.671227   \n",
      "4  0.628146   0.781992           0.709138           0.620288      0.758067   \n",
      "\n",
      "   Convex_Area    Extent  target  \n",
      "0     0.693917  0.207577       0  \n",
      "1     0.646009  0.324564       0  \n",
      "2     0.635636  0.538576       0  \n",
      "3     0.496220  0.393954       0  \n",
      "4     0.662711  0.408680       0  \n"
     ]
    }
   ],
   "source": [
    "rice = fetc(id=545)\n",
    "X = rice.data.features \n",
    "y = rice.data.targets\n",
    "df = pd.DataFrame(X, columns=rice.data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "#Change non numeric columns to numeric\n",
    "column_names = [\"Area\", \"Perimeter\", \"Major_Axis_Length\", \"Minor_Axis_Length\",\"Eccentricity\", \"Convex_Area\", \"Extent\", \"target\"]\n",
    "non_numeric_cols = df.drop(['target'],axis=1).select_dtypes(exclude=[np.number]).columns\n",
    "if not non_numeric_cols.empty:\n",
    "    for col in non_numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = StandardScaler().fit_transform(df[[col]])\n",
    "    \n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = MinMaxScaler().fit_transform(df[[col]])\n",
    "\n",
    "#Convert target column to numeric\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['target'])\n",
    "        \n",
    "df.info()\n",
    "#df.isnull().sum()\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Class: 2 which are: [0 1]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "print(\"Total number of Class: \" + str(len(np.unique(y))) + \" which are: \" + str(np.unique(y)))\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy Score:  0.9300699300699301 Training Set Accuracy Score: 0.9286596664607782\n"
     ]
    }
   ],
   "source": [
    "def clf(x_train, y_train, x_test, y_test,K):\n",
    "    clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=K, random_state=42)\n",
    "    clf_gini.fit(x_train, y_train)\n",
    "    y_pred_gini = clf_gini.predict(x_test)\n",
    "    y_pred_gini_train = clf_gini.predict(x_train)\n",
    "    print('Testing Set Accuracy Score: ', accuracy_score(y_test, y_pred_gini), 'Training Set Accuracy Score:',accuracy_score(y_train, y_pred_gini_train))\n",
    "\n",
    "clf(x_train, y_train, x_test, y_test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Structure: Will be Used for Warmstart of OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Indices:  [2, 2, 1, 2, 2, 0, 2] Threshold Indices: [0.5003375709056854, 0.4399276226758957, 0.5745012164115906, 0.3837266117334366, 0.4810698330402374, 0.4023939371109009, 0.5641956627368927]\n",
      "8\n",
      "Internal nodes: 7, Total nodes: 15\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "\"\"\"\n",
    "The following is for warm start in OCT\n",
    "\"\"\"\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "feature_indices = []\n",
    "threshold_indices = []\n",
    "feature_indices_leaf =[]\n",
    "threshold_indices_leaf = []\n",
    "for i in range(len(feature)):\n",
    "    if feature[i] != -2 and feature[i+1] != -2:\n",
    "        feature_indices.append(int(feature[i]))\n",
    "        threshold_indices.append(float(threshold[i]))\n",
    "    elif feature[i] != -2 and feature[i+1] == -2:\n",
    "        feature_indices_leaf.append(int(feature[i]))\n",
    "        threshold_indices_leaf.append(float(threshold[i]))\n",
    "    else:\n",
    "        continue\n",
    "feature_indices.extend(feature_indices_leaf)\n",
    "threshold_indices.extend(threshold_indices_leaf)\n",
    "print(\"Feature Indices: \", feature_indices, \"Threshold Indices:\", threshold_indices)\n",
    "#leaf nodes\n",
    "#branch nodes\n",
    "print(np.sum(clf.tree_.feature == -2))\n",
    "internal_nodes = np.sum(clf.tree_.feature != -2)\n",
    "total_nodes = clf.tree_.node_count\n",
    "print(f\"Internal nodes: {internal_nodes}, Total nodes: {total_nodes}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf nodes: 8, Branch nodes: 7\n"
     ]
    }
   ],
   "source": [
    "total_nodes = clf.tree_.node_count\n",
    "leaf_nodes = round(total_nodes / 2)\n",
    "branch_nodes = total_nodes // 2\n",
    "print(f\"Leaf nodes: {leaf_nodes}, Branch nodes: {branch_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCT Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.Model('OCT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraining data (X,Y)=(x_i,y_i), i=1,...,n; x_i in R^p and normalized to [0,1]^p, y_i in {1,...,K}\\n-n = # obervations\\n-p = # features\\n-K = # class label\\n\\n-p(t) = parent nodes of node t\\n-A_L(t) = {left_branch ancestors of t} = {t if tmod2=0 and t/2 recursively gives the set}\\n-A_R(t) = {right_branch ancestors of t} = {t if (t-1)mod2=0 and (t-1)/2 recursively gives the set}\\n\\n\\n-D = max depth\\n-T = 2^(D+1)-1 = max # nodes\\n-TB = branch nodes = left nodes = {1,...,floor(T/2)} applies split is ax<b \\n-TL = leaf = {floor(T/2)+1,...,T} make class prediction\\n-?a_t in R^p\\n-?b_t in R\\n-p = # features\\n\\n-d_t = 1{node t applies a split}\\n-sum a_jt = d_t, j=1,...p, t in TB\\n-0 <= b_t <= d_t, t in TB\\n-a_jt in {0,1}, j=1,...p, t in TB\\n\\n\\n-d_t <= d_p(t), t in TB/{1}\\n\\n-z_it = 1{x_i in node t}\\n-l_t = 1{leaf t contains any point}\\n-z_it <= l_t, t in TB\\n-sum(z_it) >= N_min*l_t for i=1,...,n, t in TB\\n-sum(z_it)=1 for t in TB, i=1,...,n\\n\\n-x_j^i = ith largest value in feature j\\n-epsilon_j = min{x_j^(i+1)-x_j^i, i=1,...,n}\\n-epsilon_max = max{epsilon_j} wrt j\\n-epsilon  = {epsilon_1,...,epsilon_p}\\n-a_m(x_t + epsilon) <= b_m +(1+epsilon_max)(1-z_it), i=1,...,n, for all t in TB, for all m in A_L(t)\\n-a_m*x_i >= b_m - (1-z_it), i=1,...,n, for all t in TB, for all m in A_R(t)\\n\\n-Y_ik = {1 if y_i=k, -1 otherwise}, k=1,...,K, i=1,...n\\nN_kt = 0.5*sum((1+Y_ik)z_it) for i=1,...,n; k=1,...K, t in TL\\nN_t = sum(z_it) for i=1,...,n; t in TL\\nc_t = argmax{N_kt} wrt k\\nc_kt = 1{c_t = k}\\nsum(c_kt) = l_t wrt k\\n\\nL_t = N_t - max{N_kt} wrt k = min{N_t - N_kt} wrt k\\nL_t >= N_t - N_kt - n(1-c_kt), k=1,...K, t in TL\\nL_t <= N_t - N_kt + n*c_kt, k=1,...K, t in TL\\nL_t >= 0\\n\\nL^ = baseline accuracy = #{most popular class}/n\\n\\nobjective: min (1/L^)sum(L_t) for t in TL + alpha*sum(d_t) for t in TB\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "training data (X,Y)=(x_i,y_i), i=1,...,n; x_i in R^p and normalized to [0,1]^p, y_i in {1,...,K}\n",
    "-n = # obervations\n",
    "-p = # features\n",
    "-K = # class label\n",
    "\n",
    "-p(t) = parent nodes of node t\n",
    "-A_L(t) = {left_branch ancestors of t} = {t if tmod2=0 and t/2 recursively gives the set}\n",
    "-A_R(t) = {right_branch ancestors of t} = {t if (t-1)mod2=0 and (t-1)/2 recursively gives the set}\n",
    "\n",
    "\n",
    "-D = max depth\n",
    "-T = 2^(D+1)-1 = max # nodes\n",
    "-TB = branch nodes = left nodes = {1,...,floor(T/2)} applies split is ax<b \n",
    "-TL = leaf = {floor(T/2)+1,...,T} make class prediction\n",
    "-?a_t in R^p\n",
    "-?b_t in R\n",
    "-p = # features\n",
    "\n",
    "-d_t = 1{node t applies a split}\n",
    "-sum a_jt = d_t, j=1,...p, t in TB\n",
    "-0 <= b_t <= d_t, t in TB\n",
    "-a_jt in {0,1}, j=1,...p, t in TB\n",
    "\n",
    "\n",
    "-d_t <= d_p(t), t in TB/{1}\n",
    "\n",
    "-z_it = 1{x_i in node t}\n",
    "-l_t = 1{leaf t contains any point}\n",
    "-z_it <= l_t, t in TB\n",
    "-sum(z_it) >= N_min*l_t for i=1,...,n, t in TB\n",
    "-sum(z_it)=1 for t in TB, i=1,...,n\n",
    "\n",
    "-x_j^i = ith largest value in feature j\n",
    "-epsilon_j = min{x_j^(i+1)-x_j^i, i=1,...,n}\n",
    "-epsilon_max = max{epsilon_j} wrt j\n",
    "-epsilon  = {epsilon_1,...,epsilon_p}\n",
    "-a_m(x_t + epsilon) <= b_m +(1+epsilon_max)(1-z_it), i=1,...,n, for all t in TB, for all m in A_L(t)\n",
    "-a_m*x_i >= b_m - (1-z_it), i=1,...,n, for all t in TB, for all m in A_R(t)\n",
    "\n",
    "-Y_ik = {1 if y_i=k, -1 otherwise}, k=1,...,K, i=1,...n\n",
    "N_kt = 0.5*sum((1+Y_ik)z_it) for i=1,...,n; k=1,...K, t in TL\n",
    "N_t = sum(z_it) for i=1,...,n; t in TL\n",
    "c_t = argmax{N_kt} wrt k\n",
    "c_kt = 1{c_t = k}\n",
    "sum(c_kt) = l_t wrt k\n",
    "\n",
    "L_t = N_t - max{N_kt} wrt k = min{N_t - N_kt} wrt k\n",
    "L_t >= N_t - N_kt - n(1-c_kt), k=1,...K, t in TL\n",
    "L_t <= N_t - N_kt + n*c_kt, k=1,...K, t in TL\n",
    "L_t >= 0\n",
    "\n",
    "L^ = baseline accuracy = #{most popular class}/n\n",
    "\n",
    "objective: min (1/L^)sum(L_t) for t in TL + alpha*sum(d_t) for t in TB\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predetermined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.801267382496647e-05, 5.1572260014176585e-06, 3.253471011488429e-07, 1.5892507770898234e-07, 3.454851569273387e-07, 8.790436005612356e-05, 1.649998595532054e-07]\n"
     ]
    }
   ],
   "source": [
    "n= df.shape[0] # number of observations\n",
    "p = df.drop(['target'],axis=1).shape[1] # number of features\n",
    "K = len(np.unique(df['target'])) # number of classes\n",
    "D = 3 # max depth\n",
    "T = 2**(D+1)-1 # max number of nodes\n",
    "L_hat = df['target'].value_counts().max()/n # baseline accuracy\n",
    "\n",
    "N_min = math.floor(n*0.05)\n",
    "\n",
    "#Epsilon\n",
    "epsilon=[]\n",
    "for j in range(p):\n",
    "    x_j = df.iloc[:,j].tolist()\n",
    "    x_j.sort()  \n",
    "    e=[]\n",
    "    for i in range(n-1):\n",
    "        if x_j[i+1]!=x_j[i]:\n",
    "            e.append(x_j[i+1] - x_j[i])\n",
    "    epsilon.append(min(e))\n",
    "epsilon_max = max(epsilon)\n",
    "\n",
    "#Y Matrix\n",
    "Y = np.zeros([n,K], dtype = int) - 1 # Y_ik\n",
    "Y[df.index,  y] = 1  #based on the sample code, the [x,y] x is the features index, y is the class index\n",
    "print(epsilon)\n",
    "\n",
    "#label_to_binary = {'Cammeo': 1, 'Osmancik': 0}\n",
    "#y_binary = np.array([label_to_binary[label] for label in y])\n",
    "#print(\"y binary: \" + str(y_binary)) \n",
    "#Y_ik = np.zeros([n,K], dtype = int) - 1\n",
    "#Y_ik[df.index,  y] = 1  #based on the sample code, the [x,y] x is the features index, y is the class index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predetermined Sets (Note that index starts from 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7]\n",
      "Branch nodes:  [1, 2, 3, 4, 5, 6, 7]\n",
      "Leaf nodes:  [8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [1],\n",
       " [],\n",
       " [2],\n",
       " [1],\n",
       " [3, 1],\n",
       " [],\n",
       " [4],\n",
       " [2],\n",
       " [5, 2],\n",
       " [1],\n",
       " [6, 1],\n",
       " [3, 1],\n",
       " [7, 3, 1]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent = []\n",
    "for t in range(1,T+1):\n",
    "    if t%2==0:\n",
    "        parent.append(t//2)\n",
    "    else:\n",
    "        parent.append((t-1)//2)\n",
    "print(parent)\n",
    "\n",
    "left_ancestors = []\n",
    "right_ancestors = []\n",
    "for t in range(1,T+1):\n",
    "    la_t =[]\n",
    "    ra_t =[]\n",
    "    tau=t\n",
    "    while tau>1:\n",
    "        pt = tau//2\n",
    "        if tau % 2 == 0: #if t is even, then its parent is a left ancestor, else is a right ancestor\n",
    "            la_t.append(pt)\n",
    "        else:\n",
    "            ra_t.append(pt)\n",
    "        tau = pt\n",
    "    left_ancestors.append(la_t)\n",
    "    right_ancestors.append(ra_t)\n",
    "\n",
    "TB = list(range(1,math.floor((T+1)/2)))  #Branch nodes\n",
    "TL = list(range(math.floor((T+1)/2),T+1)) #Leaf nodes\n",
    "TT = list(range(1,T+1)) #total nodes\n",
    "print(\"Branch nodes: \", TB)\n",
    "print(\"Leaf nodes: \", TL)\n",
    "left_ancestors\n",
    "right_ancestors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables and Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updated Variables and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m.addVars(p,TB, vtype=GRB.BINARY, name=\"a_t\") #dim |TB|xp\n",
    "b = m.addVars(TB, vtype=GRB.CONTINUOUS, lb = 0, ub = 1, name=\"b_t\") #dim |TB| ###\n",
    "d = m.addVars(TB, vtype=GRB.BINARY, name=\"d_t\") #dim |TB|\n",
    "z = m.addVars(n, TL, vtype=GRB.BINARY, name=\"z\") #dim nx|TL|\n",
    "l = m.addVars(TL, vtype=GRB.BINARY, name=\"l_t\") #dim |TL|\n",
    "Nk = m.addVars(K, TL, vtype=GRB.INTEGER,name=\"N_kt\") #dim Kx|TL|\n",
    "N = m.addVars(TL, vtype=GRB.INTEGER, name=\"N_t\") #dim |TL|\n",
    "ck = m.addVars(K, TL, vtype=GRB.BINARY, name=\"c_kt\")\n",
    "# c = m.addVars(TL, vtype=GRB.INTEGER, name=\"c_t\") #dim |TL|\n",
    "#c_bin = m.addVars(K, TL, vtype=GRB.BINARY, name=\"c_bin\") #dim Kx|TL|\n",
    "L = m.addVars(TL, name=\"L_t\") \n",
    "\n",
    "for t in TB:\n",
    "    m.addConstr(gp.quicksum(a[i,t] for i in range(p)) == d[t], name=\"sum_constraint_of_ajt\") # sum of ajt = dt\n",
    "    # m.addConstr(b[t] >= 0, name=\"bt_constraint_0\")         # 0 <= bt\n",
    "    m.addConstr(b[t] <= d[t], name=\"bt_constraint_dt\")     # bt <= dt\n",
    "\n",
    "for t in TB[1:]:\n",
    "    m.addConstr(d[t] <= d[t//2], name=\"dt_constraint_dp(t)\") # dt <= dp(t) \n",
    "    \n",
    "# for t in TB:\n",
    "#     m.addConstr(d[t] == 1, name=\"dt_constraint_d(t)\") \n",
    "    \n",
    "# for t in TL:\n",
    "#     m.addConstr(l[t] == 1, name=\"dt_constraint_l(t)\")\n",
    "\n",
    "for t in TL:\n",
    "    for i in range(n):\n",
    "        m.addConstr(z[i, t] <= l[t]) # zit <= lt\n",
    "\n",
    "for t in TL:\n",
    "    m.addConstr(gp.quicksum(z[i,t] for i in range(n)) >= N_min*l[t], name=\"sum_of_zt_constraint_Nmin_lt\") # sum of zit >= Nmin*lt\n",
    "    \n",
    "for i in range(n):\n",
    "    m.addConstr(gp.quicksum(z[i,t] for t in TL) == 1, name=\"sum_of_zi(t)_constraint_1\")  # sum sum of zit = 1\n",
    "\n",
    "\n",
    "for t in TL:\n",
    "    for k in range(K):\n",
    "        m.addConstr(Nk[k,t] == 1/2 * gp.quicksum(z[i,t] * (Y[i,k] + 1) for i in range(n))) #Nkt = 1/2(sum of (1+Yik)*zit #may need to be corrected\n",
    "         \n",
    "for t in TL:\n",
    "    m.addConstr(N[t] == gp.quicksum(z[i, t] for i in range(n)))  # Nt = sum of zit\n",
    "\n",
    "for t in TL:\n",
    "    m.addConstr(l[t] == gp.quicksum(ck[k, t] for k in range(K))) # sum of ckt = lt\n",
    "    \n",
    "for t in TL:\n",
    "    if len(left_ancestors[t-1]) != 0:\n",
    "        for la in left_ancestors[t-1]:\n",
    "            for i in range(n):\n",
    "                axe = sum([(a[j,la])*(X.iloc[i].tolist()[j] + epsilon[j]) for j in range(p)])\n",
    "                m.addConstr(axe <= b[la] + (1 + epsilon_max) * (1 - z[i,t]), name=\"split_structure_constraint_l_i\")\n",
    "                \n",
    "    if len(right_ancestors[t-1]) != 0:\n",
    "        for r in right_ancestors[t-1]:\n",
    "            for i in range(n):\n",
    "                ade = sum([(a[j,r])*(X.iloc[i].tolist()[j]) for j in range(p)])\n",
    "                m.addConstr(ade >= b[r] - (1 - z[i,t]), name=\"split_structure_constraint_r_i\")\n",
    "\n",
    "#for t in TL:\n",
    "    #m.addConstr(gp.quicksum(c_bin[k, t] for k in range(K)) == 1, name=f\"unique_selection_t\")\n",
    "#for t in TL:\n",
    "    #for k in range(K):\n",
    "        #m.addConstr(c[t] >= k - (1 - c_bin[k, t]) * K, name=f\"select_max_kt\")\n",
    "        #m.addConstr(c[t] <= k + (1 - c_bin[k, t])* K, name=f\"select_min_kt\")\n",
    "        \n",
    "for t in TL:\n",
    "    for k in range(K):\n",
    "        m.addConstr(L[t] >= N[t] - Nk[k,t] - n*(1-ck[k,t]), name=\"Lt_constraint1\") #Lt ≤ Nt − Nkt + n(1-ckt) \n",
    "        m.addConstr(L[t] <= N[t] - Nk[k,t] + n*ck[k,t], name=\"Lt_constraint2\")  #Lt ≤ Nt − Nkt + n*ckt \n",
    "    m.addConstr(L[t] >= 0, name=\"Lt_constraint3\") #Lt ≥ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: <gurobi.Var *Awaiting Model Update*>,\n",
       " 9: <gurobi.Var *Awaiting Model Update*>,\n",
       " 10: <gurobi.Var *Awaiting Model Update*>,\n",
       " 11: <gurobi.Var *Awaiting Model Update*>,\n",
       " 12: <gurobi.Var *Awaiting Model Update*>,\n",
       " 13: <gurobi.Var *Awaiting Model Update*>,\n",
       " 14: <gurobi.Var *Awaiting Model Update*>,\n",
       " 15: <gurobi.Var *Awaiting Model Update*>}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) Ultra 9 185H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 22 logical processors, using up to 22 threads\n",
      "\n",
      "Optimize a model with 2344963 rows, 581453 columns and 16805688 nonzeros\n",
      "Model fingerprint: 0x30298d59\n",
      "Variable types: 285 continuous, 581168 integer (580688 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-07, 4e+03]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [5e-01, 4e+03]\n",
      "Presolve removed 484949 rows and 103331 columns\n",
      "Presolve time: 1.29s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 2.85 seconds (4.87 work units)\n",
      "Thread count was 1 (of 22 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n"
     ]
    }
   ],
   "source": [
    "m.setObjective(gp.quicksum(L[t]/L_hat for t in TL) + 0.5*gp.quicksum(d[t] for t in TB), GRB.MINIMIZE) #minimize L + alpha*sum(d_t) for t in TB\n",
    "\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is infeasible. Computing IIS...\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) Ultra 9 185H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 22 logical processors, using up to 22 threads\n",
      "\n",
      "\n",
      "Computing Irreducible Inconsistent Subsystem (IIS)...\n",
      "\n",
      "           Constraints          |            Bounds           |  Runtime\n",
      "      Min       Max     Guess   |   Min       Max     Guess   |\n",
      "--------------------------------------------------------------------------\n",
      "        0   2131603         -         0       821         -           0s\n",
      "        0   2131603         -         0       821         -          29s\n",
      "        0     34337         -         0        11         -          37s\n",
      "        0     18250         -         0         8         -          40s\n",
      "        0      7857         -         0         6         -          45s\n",
      "        1      5155         -         0         4         -          51s\n",
      "        2      3384         -         0         3         -          55s\n",
      "        3      1185         -         0         3         -          61s\n",
      "        3       404         -         0         2         -          65s\n",
      "        3       132         3         0         2         -          70s\n",
      "        4        56         4         0         2         -          75s\n",
      "        4        44         4         0         2         -          80s\n",
      "        6        36         6         0         2         -          85s\n",
      "        6        26         6         0         2         -          90s\n",
      "        8        19         8         0         2         -          96s\n",
      "        8        11         8         0         2         -         100s\n",
      "        9         9         9         2         2         2         104s\n",
      "\n",
      "IIS computed: 9 constraints, 2 bounds\n",
      "IIS runtime: 104.26 seconds (70.92 work units)\n"
     ]
    }
   ],
   "source": [
    "if m.status == gp.GRB.INFEASIBLE:\n",
    "    print(\"Model is infeasible. Computing IIS...\")\n",
    "    m.computeIIS()\n",
    "    m.write(\"infeasible_model.ilp\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infeasible Constraint: sum_of_zi(t)_constraint_1\n",
      "Infeasible Constraint: split_structure_constraint_l_i\n",
      "Infeasible Constraint: split_structure_constraint_l_i\n",
      "Infeasible Constraint: split_structure_constraint_r_i\n",
      "Infeasible Constraint: split_structure_constraint_r_i\n",
      "Infeasible Constraint: split_structure_constraint_r_i\n",
      "Infeasible Constraint: split_structure_constraint_r_i\n",
      "Infeasible Constraint: split_structure_constraint_r_i\n",
      "Infeasible Constraint: split_structure_constraint_r_i\n",
      "Infeasible Bound on Variable: b_t[1]\n",
      "Infeasible Bound on Variable: b_t[7]\n"
     ]
    }
   ],
   "source": [
    "for c in m.getConstrs():\n",
    "    if c.IISConstr:\n",
    "        print(f\"Infeasible Constraint: {c.constrName}\")\n",
    "\n",
    "for v in m.getVars():\n",
    "    if v.IISLB or v.IISUB:\n",
    "        print(f\"Infeasible Bound on Variable: {v.varName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <gurobi.Var b_t[1]>,\n",
       " 2: <gurobi.Var b_t[2]>,\n",
       " 3: <gurobi.Var b_t[3]>,\n",
       " 4: <gurobi.Var b_t[4]>,\n",
       " 5: <gurobi.Var b_t[5]>,\n",
       " 6: <gurobi.Var b_t[6]>,\n",
       " 7: <gurobi.Var b_t[7]>}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [1],\n",
       " [],\n",
       " [2, 1],\n",
       " [1],\n",
       " [3],\n",
       " [],\n",
       " [4, 2, 1],\n",
       " [2, 1],\n",
       " [5, 1],\n",
       " [1],\n",
       " [6, 3],\n",
       " [3],\n",
       " [7],\n",
       " []]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_ancestors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
