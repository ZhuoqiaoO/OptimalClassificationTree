{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "from gurobipy import *\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from ucimlrepo import fetch_ucirepo as fetc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Check Data Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Area               3000 non-null   float64\n",
      " 1   Perimeter          3000 non-null   float64\n",
      " 2   Major_Axis_Length  3000 non-null   float64\n",
      " 3   Minor_Axis_Length  3000 non-null   float64\n",
      " 4   Eccentricity       3000 non-null   float64\n",
      " 5   Convex_Area        3000 non-null   float64\n",
      " 6   Extent             3000 non-null   float64\n",
      " 7   target             3000 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 187.6 KB\n",
      "       Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
      "0  0.430470   0.530431           0.453409           0.576023      0.644061   \n",
      "1  0.427478   0.411490           0.370038           0.610231      0.548847   \n",
      "2  0.467875   0.475215           0.391069           0.662542      0.519751   \n",
      "3  0.487502   0.601254           0.615399           0.493600      0.801364   \n",
      "4  0.247140   0.266237           0.301313           0.361245      0.709309   \n",
      "\n",
      "   Convex_Area    Extent  target  \n",
      "0     0.458685  0.246586       0  \n",
      "1     0.428534  0.382542       1  \n",
      "2     0.477233  0.415970       1  \n",
      "3     0.492968  0.763732       0  \n",
      "4     0.244989  0.208039       1  \n"
     ]
    }
   ],
   "source": [
    "rice = fetc(id=545)\n",
    "X = rice.data.features \n",
    "y = rice.data.targets\n",
    "df = pd.DataFrame(X, columns=rice.data.feature_names).sample(n=3000, random_state=42)\n",
    "df['target'] = y\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Change non numeric columns to numeric\n",
    "column_names = [\"Area\", \"Perimeter\", \"Major_Axis_Length\", \"Minor_Axis_Length\",\"Eccentricity\", \"Convex_Area\", \"Extent\", \"target\"]\n",
    "non_numeric_cols = df.drop(['target'],axis=1).select_dtypes(exclude=[np.number]).columns\n",
    "if not non_numeric_cols.empty:\n",
    "    for col in non_numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = StandardScaler().fit_transform(df[[col]])\n",
    "    \n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = MinMaxScaler().fit_transform(df[[col]])\n",
    "\n",
    "#Convert target column to numeric\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['target'])\n",
    "        \n",
    "df.info()\n",
    "#df.isnull().sum()\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Class: 2 which are: [0 1]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "print(\"Total number of Class: \" + str(len(np.unique(y))) + \" which are: \" + str(np.unique(y)))\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy Score:  0.9111111111111111 Training Set Accuracy Score: 0.9341176470588235\n"
     ]
    }
   ],
   "source": [
    "def clf(x_train, y_train, x_test, y_test,K):\n",
    "    clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=K, random_state=42)\n",
    "    clf_gini.fit(x_train, y_train)\n",
    "    y_pred_gini = clf_gini.predict(x_test)\n",
    "    y_pred_gini_train = clf_gini.predict(x_train)\n",
    "    print('Testing Set Accuracy Score: ', accuracy_score(y_test, y_pred_gini), 'Training Set Accuracy Score:',accuracy_score(y_train, y_pred_gini_train))\n",
    "\n",
    "clf(x_train, y_train, x_test, y_test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Structure: Will be Used for Warmstart of OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Indices:  [2, 2, 2, 2, 2, 5, 2] Threshold Indices: [0.5125517845153809, 0.44264456629753113, 0.5738876163959503, 0.38609644770622253, 0.47788456082344055, 0.5260196924209595, 0.6545738279819489]\n",
      "8\n",
      "Internal nodes: 7, Total nodes: 15\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "\"\"\"\n",
    "The following is for warm start in OCT\n",
    "\"\"\"\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "feature_indices = []\n",
    "threshold_indices = []\n",
    "feature_indices_leaf =[]\n",
    "threshold_indices_leaf = []\n",
    "for i in range(len(feature)):\n",
    "    if feature[i] != -2 and feature[i+1] != -2:\n",
    "        feature_indices.append(int(feature[i]))\n",
    "        threshold_indices.append(float(threshold[i]))\n",
    "    elif feature[i] != -2 and feature[i+1] == -2:\n",
    "        feature_indices_leaf.append(int(feature[i]))\n",
    "        threshold_indices_leaf.append(float(threshold[i]))\n",
    "    else:\n",
    "        continue\n",
    "feature_indices.extend(feature_indices_leaf)\n",
    "threshold_indices.extend(threshold_indices_leaf)\n",
    "print(\"Feature Indices: \", feature_indices, \"Threshold Indices:\", threshold_indices)\n",
    "#leaf nodes\n",
    "#branch nodes\n",
    "print(np.sum(clf.tree_.feature == -2))\n",
    "internal_nodes = np.sum(clf.tree_.feature != -2)\n",
    "total_nodes = clf.tree_.node_count\n",
    "print(f\"Internal nodes: {internal_nodes}, Total nodes: {total_nodes}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf nodes: 8, Branch nodes: 7\n"
     ]
    }
   ],
   "source": [
    "total_nodes = clf.tree_.node_count\n",
    "leaf_nodes = round(total_nodes / 2)\n",
    "branch_nodes = total_nodes // 2\n",
    "print(f\"Leaf nodes: {leaf_nodes}, Branch nodes: {branch_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCT Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.Model('OCT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraining data (X,Y)=(x_i,y_i), i=1,...,n; x_i in R^p and normalized to [0,1]^p, y_i in {1,...,K}\\n-n = # obervations\\n-p = # features\\n-K = # class label\\n\\n-p(t) = parent nodes of node t\\n-A_L(t) = {left_branch ancestors of t} = {t if tmod2=0 and t/2 recursively gives the set}\\n-A_R(t) = {right_branch ancestors of t} = {t if (t-1)mod2=0 and (t-1)/2 recursively gives the set}\\n\\n\\n-D = max depth\\n-T = 2^(D+1)-1 = max # nodes\\n-TB = branch nodes = left nodes = {1,...,floor(T/2)} applies split is ax<b \\n-TL = leaf = {floor(T/2)+1,...,T} make class prediction\\n-?a_t in R^p\\n-?b_t in R\\n-p = # features\\n\\n-d_t = 1{node t applies a split}\\n-sum a_jt = d_t, j=1,...p, t in TB\\n-0 <= b_t <= d_t, t in TB\\n-a_jt in {0,1}, j=1,...p, t in TB\\n\\n\\n-d_t <= d_p(t), t in TB/{1}\\n\\n-z_it = 1{x_i in node t}\\n-l_t = 1{leaf t contains any point}\\n-z_it <= l_t, t in TB\\n-sum(z_it) >= N_min*l_t for i=1,...,n, t in TB\\n-sum(z_it)=1 for t in TB, i=1,...,n\\n\\n-x_j^i = ith largest value in feature j\\n-epsilon_j = min{x_j^(i+1)-x_j^i, i=1,...,n}\\n-epsilon_max = max{epsilon_j} wrt j\\n-epsilon  = {epsilon_1,...,epsilon_p}\\n-a_m(x_t + epsilon) <= b_m +(1+epsilon_max)(1-z_it), i=1,...,n, for all t in TB, for all m in A_L(t)\\n-a_m*x_i >= b_m - (1-z_it), i=1,...,n, for all t in TB, for all m in A_R(t)\\n\\n-Y_ik = {1 if y_i=k, -1 otherwise}, k=1,...,K, i=1,...n\\nN_kt = 0.5*sum((1+Y_ik)z_it) for i=1,...,n; k=1,...K, t in TL\\nN_t = sum(z_it) for i=1,...,n; t in TL\\nc_t = argmax{N_kt} wrt k\\nc_kt = 1{c_t = k}\\nsum(c_kt) = l_t wrt k\\n\\nL_t = N_t - max{N_kt} wrt k = min{N_t - N_kt} wrt k\\nL_t >= N_t - N_kt - n(1-c_kt), k=1,...K, t in TL\\nL_t <= N_t - N_kt + n*c_kt, k=1,...K, t in TL\\nL_t >= 0\\n\\nL^ = baseline accuracy = #{most popular class}/n\\n\\nobjective: min (1/L^)sum(L_t) for t in TL + alpha*sum(d_t) for t in TB\\n\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "training data (X,Y)=(x_i,y_i), i=1,...,n; x_i in R^p and normalized to [0,1]^p, y_i in {1,...,K}\n",
    "-n = # obervations\n",
    "-p = # features\n",
    "-K = # class label\n",
    "\n",
    "-p(t) = parent nodes of node t\n",
    "-A_L(t) = {left_branch ancestors of t} = {t if tmod2=0 and t/2 recursively gives the set}\n",
    "-A_R(t) = {right_branch ancestors of t} = {t if (t-1)mod2=0 and (t-1)/2 recursively gives the set}\n",
    "\n",
    "\n",
    "-D = max depth\n",
    "-T = 2^(D+1)-1 = max # nodes\n",
    "-TB = branch nodes = left nodes = {1,...,floor(T/2)} applies split is ax<b \n",
    "-TL = leaf = {floor(T/2)+1,...,T} make class prediction\n",
    "-?a_t in R^p\n",
    "-?b_t in R\n",
    "-p = # features\n",
    "\n",
    "-d_t = 1{node t applies a split}\n",
    "-sum a_jt = d_t, j=1,...p, t in TB\n",
    "-0 <= b_t <= d_t, t in TB\n",
    "-a_jt in {0,1}, j=1,...p, t in TB\n",
    "\n",
    "\n",
    "-d_t <= d_p(t), t in TB/{1}\n",
    "\n",
    "-z_it = 1{x_i in node t}\n",
    "-l_t = 1{leaf t contains any point}\n",
    "-z_it <= l_t, t in TB\n",
    "-sum(z_it) >= N_min*l_t for i=1,...,n, t in TB\n",
    "-sum(z_it)=1 for t in TB, i=1,...,n\n",
    "\n",
    "-x_j^i = ith largest value in feature j\n",
    "-epsilon_j = min{x_j^(i+1)-x_j^i, i=1,...,n}\n",
    "-epsilon_max = max{epsilon_j} wrt j\n",
    "-epsilon  = {epsilon_1,...,epsilon_p}\n",
    "-a_m(x_t + epsilon) <= b_m +(1+epsilon_max)(1-z_it), i=1,...,n, for all t in TB, for all m in A_L(t)\n",
    "-a_m*x_i >= b_m - (1-z_it), i=1,...,n, for all t in TB, for all m in A_R(t)\n",
    "\n",
    "-Y_ik = {1 if y_i=k, -1 otherwise}, k=1,...,K, i=1,...n\n",
    "N_kt = 0.5*sum((1+Y_ik)z_it) for i=1,...,n; k=1,...K, t in TL\n",
    "N_t = sum(z_it) for i=1,...,n; t in TL\n",
    "c_t = argmax{N_kt} wrt k\n",
    "c_kt = 1{c_t = k}\n",
    "sum(c_kt) = l_t wrt k\n",
    "\n",
    "L_t = N_t - max{N_kt} wrt k = min{N_t - N_kt} wrt k\n",
    "L_t >= N_t - N_kt - n(1-c_kt), k=1,...K, t in TL\n",
    "L_t <= N_t - N_kt + n*c_kt, k=1,...K, t in TL\n",
    "L_t >= 0\n",
    "\n",
    "L^ = baseline accuracy = #{most popular class}/n\n",
    "\n",
    "objective: min (1/L^)sum(L_t) for t in TL + alpha*sum(d_t) for t in TB\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predetermined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: [8.801267382496647e-05, 5.157226001362147e-06, 3.273563998762441e-07, 1.5892507770898234e-07, 3.5751314475529483e-07, 8.790436005612356e-05, 1.6530101976108824e-07]\n",
      "epsilon_max: 8.801267382496647e-05\n"
     ]
    }
   ],
   "source": [
    "n= df.shape[0] # number of observations\n",
    "p = df.drop(['target'],axis=1).shape[1] # number of features\n",
    "K = len(np.unique(df['target'])) # number of classes\n",
    "D = 3 # max depth\n",
    "T = 2**(D+1)-1 # max number of nodes\n",
    "L_hat = df['target'].value_counts().max()/n # baseline accuracy, predicting the most popular class for the dataset\n",
    "\n",
    "N_min = math.floor(n*0.05)\n",
    "\n",
    "#Epsilon\n",
    "epsilon=[]\n",
    "for j in range(p):\n",
    "    x_j = df.iloc[:,j].tolist()\n",
    "    x_j.sort()  \n",
    "    e=[]\n",
    "    for i in range(n-1):\n",
    "        if x_j[i+1]!=x_j[i]:\n",
    "            e.append(x_j[i+1] - x_j[i])\n",
    "    epsilon.append(min(e))\n",
    "epsilon_max = max(epsilon)\n",
    "\n",
    "print(\"epsilon: \" + str(epsilon))\n",
    "print(\"epsilon_max: \" + str(epsilon_max))\n",
    "\n",
    "#Y Matrix\n",
    "Y = np.zeros([n,K], dtype = int) - 1 # Y_ik\n",
    "Y[df.index,  y] = 1  #based on the sample code, the [x,y] x is the features index, y is the class index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predetermined Sets (Note that index starts from 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7]\n",
      "Branch nodes:  [1, 2, 3, 4, 5, 6, 7]\n",
      "Leaf nodes:  [8, 9, 10, 11, 12, 13, 14, 15]\n",
      "left_ancestors: [[], [1], [], [1, 2], [1], [3], [], [1, 2, 4], [1, 2], [1, 5], [1], [3, 6], [3], [7], []]\n",
      "right_ancestors: [[], [], [1], [], [2], [1], [1, 3], [], [4], [2], [2, 5], [1], [1, 6], [1, 3], [1, 3, 7]]\n"
     ]
    }
   ],
   "source": [
    "parent = []\n",
    "for t in range(1,T+1):\n",
    "    if t%2==0:\n",
    "        parent.append(t//2)\n",
    "    else:\n",
    "        parent.append((t-1)//2)\n",
    "print(parent)\n",
    "\n",
    "left_ancestors = []\n",
    "right_ancestors = []\n",
    "for t in range(1,T+1):\n",
    "    la_t =[]\n",
    "    ra_t =[]\n",
    "    tau=t\n",
    "    while tau>1:\n",
    "        pt = tau//2\n",
    "        if tau % 2 == 0: #if t is even, then its parent is a left ancestor, else is a right ancestor\n",
    "            la_t.append(pt)\n",
    "        else:\n",
    "            ra_t.append(pt)\n",
    "        tau = pt\n",
    "    la_t.sort() \n",
    "    ra_t.sort()\n",
    "    left_ancestors.append(la_t)\n",
    "    right_ancestors.append(ra_t)\n",
    "\n",
    "TB = list(range(1,math.floor((T+1)/2)))  #Branch nodes\n",
    "TL = list(range(math.floor((T+1)/2),T+1)) #Leaf nodes\n",
    "TT = list(range(1,T+1)) #total nodes\n",
    "\n",
    "print(\"Branch nodes: \", TB)\n",
    "print(\"Leaf nodes: \", TL)\n",
    "\n",
    "print(\"left_ancestors: \" + str(left_ancestors))\n",
    "print(\"right_ancestors: \" + str(right_ancestors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m.addVars(p,TB, vtype=GRB.BINARY, name=\"a_t\") #dim |TB|xp\n",
    "b = m.addVars(TB, vtype=GRB.CONTINUOUS, lb = 0, ub = 1, name=\"b_t\") #dim |TB|\n",
    "d = m.addVars(TB, vtype=GRB.BINARY, name=\"d_t\") #dim |TB|\n",
    "z = m.addVars(n, TL, vtype=GRB.BINARY, name=\"z\") #dim nx|TL|\n",
    "l = m.addVars(TL, vtype=GRB.BINARY, name=\"l_t\") #dim |TL|\n",
    "Nk = m.addVars(K, TL, vtype=GRB.INTEGER,name=\"N_kt\") #dim Kx|TL|\n",
    "N = m.addVars(TL, vtype=GRB.INTEGER, name=\"N_t\") #dim |TL|\n",
    "ck = m.addVars(K, TL, vtype=GRB.BINARY, name=\"c_kt\")\n",
    "L = m.addVars(TL, name=\"L_t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm start using the results of CART algorithm\n",
    "for i in TB:\n",
    "    a[feature_indices[i-1], i].start = 1\n",
    "    b[i].start = threshold_indices[i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in TB:\n",
    "    m.addConstr(a.sum(\"*\",t) == d[t], name=\"sum_constraint_of_ajt\") # sum of ajt = dt\n",
    "    m.addConstr(b[t] <= d[t], name=\"bt_constraint_dt\")     # bt <= dt\n",
    "    m.addConstr(d[t] == 1, name=\"dt_constraint_d(t)\")  #force dt = 1???\n",
    "\n",
    "for t in TB[1:]:\n",
    "    m.addConstr(d[t] <= d[t//2], name=\"dt_constraint_dp(t)\") # dt <= dp(t)    \n",
    "\n",
    "for t in TL:\n",
    "    m.addConstr(z.sum(\"*\",t) >= N_min*l[t], name=\"sum_of_zt_constraint_Nmin_lt\") # sum of zit >= Nmin*lt\n",
    "    m.addConstr(z.sum(i,\"*\") == 1, name=\"sum_of_zi(t)_constraint_1\")  # sum sum of zit = 1\n",
    "    for i in range(n):\n",
    "        m.addConstr(z[i, t] <= l[t]) # zit <= lt\n",
    "    \n",
    "    for k in range(K):\n",
    "        m.addConstr(Nk[k,t] == 1/2 * gp.quicksum(z[i,t] * (Y[i,k] + 1) for i in range(n))) #Nkt = 1/2(sum of (1+Yik)*zit #may need to be corrected\n",
    "\n",
    "    m.addConstr(N[t] == z.sum(\"*\",t))  # Nt = sum of zit\n",
    "\n",
    "    m.addConstr(l[t] == ck.sum(\"*\",t)) # sum of ckt = lt\n",
    "    \n",
    "    m.addConstr(l[t] == 1, name=\"dt_constraint_l(t)\")\n",
    "    \n",
    "for t in TL:\n",
    "    l_ancestors = left_ancestors[t - 1]  # cache the list\n",
    "    if l_ancestors:\n",
    "        for la in l_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X.iloc[i]  # cache row once\n",
    "                m.addConstr(gp.quicksum(a[j, la] * (xi[j] + epsilon[j]) for j in range(p)) <= b[la] + (1 + epsilon_max) * (1 - z[i, t]),\n",
    "                    name=f\"split_l_{la}_{i}_{t}\"\n",
    "                )\n",
    "                \n",
    "    r_ancestors = right_ancestors[t - 1]\n",
    "    if r_ancestors:\n",
    "        for r in r_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X.iloc[i]  # cache the row once\n",
    "                m.addConstr(\n",
    "                    gp.quicksum(a[j, r] * xi[j] for j in range(p)) >= b[r] - (1 - z[i, t]),\n",
    "                    name=f\"split_r_{r}_{i}_{t}\"\n",
    "                )\n",
    "        \n",
    "for t in TL:\n",
    "    m.addConstr(L[t] >= 0, name=\"Lt_constraint3\") #Lt ≥ 0\n",
    "    for k in range(K):\n",
    "        m.addConstr(L[t] >= N[t] - Nk[k,t] - n*(1-ck[k,t]), name=\"Lt_constraint1\") #Lt ≤ Nt − Nkt + n(1-ckt) \n",
    "        m.addConstr(L[t] <= N[t] - Nk[k,t] + n*ck[k,t], name=\"Lt_constraint2\")  #Lt ≤ Nt − Nkt + n*ckt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update()\n",
    "m.setObjective(L.sum('*') / L_hat + 0.5*gp.quicksum(d[t] for t in TB), GRB.MINIMIZE) #minimize L + alpha*sum(d_t) for t in TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 600\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) Ultra 9 185H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 22 logical processors, using up to 22 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  600\n",
      "\n",
      "Optimize a model with 96123 rows, 24119 columns and 768269 nonzeros\n",
      "Model fingerprint: 0x694541ec\n",
      "Variable types: 15 continuous, 24104 integer (24080 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-07, 3e+03]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "\n",
      "Warning: Completing partial solution with 24097 unfixed non-continuous variables out of 24104\n",
      "User MIP start did not produce a new incumbent solution\n",
      "\n",
      "Presolve removed 24066 rows and 31 columns\n",
      "Presolve time: 0.99s\n",
      "Presolved: 72057 rows, 24088 columns, 672117 nonzeros\n",
      "Variable types: 7 continuous, 24081 integer (24057 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal simplex, dual simplex, and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Root barrier log...\n",
      "\n",
      "Ordering time: 0.10s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 56\n",
      " AA' NZ     : 7.201e+05\n",
      " Factor NZ  : 1.947e+06 (roughly 60 MB of memory)\n",
      " Factor Ops : 5.266e+07 (less than 1 second per iteration)\n",
      " Threads    : 13\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   1.79082273e+04 -1.31139662e+06  1.39e+03 6.35e+00  3.07e+02     2s\n",
      "   1   1.20697816e+04 -2.33729208e+06  1.06e+03 2.72e-09  2.14e+02     3s\n",
      "   2   1.96688129e+03 -2.10447389e+06  4.70e+01 1.69e-01  2.45e+01     3s\n",
      "   3   7.56115161e+02 -1.11410117e+06  1.80e+01 6.48e-02  1.09e+01     3s\n",
      "   4   1.24700177e+01 -3.26155025e+05  2.54e-02 6.89e-10  2.73e+00     3s\n",
      "   5   3.50005886e+00  1.89002739e+00  3.90e-10 8.41e-08  1.35e-05     3s\n",
      "   6   3.50000000e+00  3.49999839e+00  6.39e-13 6.65e-14  1.35e-11     3s\n",
      "   7   3.50000000e+00  3.49999998e+00  1.01e-12 5.22e-08  1.77e-13     3s\n",
      "   8   3.50000000e+00  3.50000000e+00  2.34e-13 1.71e-09  1.78e-16     3s\n",
      "\n",
      "Barrier solved model in 8 iterations and 2.93 seconds (2.28 work units)\n",
      "Optimal objective 3.50000000e+00\n",
      "\n",
      "Concurrent spin time: 0.62s (can be avoided by choosing Method=3)\n",
      "\n",
      "Solved with primal simplex\n",
      "\n",
      "Root relaxation: objective 3.500000e+00, 4278 iterations, 1.34 seconds (0.63 work units)\n",
      "Total elapsed time = 5.24s (DegenMoves)\n",
      "Total elapsed time = 11.96s (DegenMoves)\n",
      "Another try with MIP start\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    3.50000    0  357          -    3.50000      -     -   12s\n",
      "     0     0    3.50000    0  415          -    3.50000      -     -   15s\n",
      "     0     0    3.50000    0  444          -    3.50000      -     -   16s\n",
      "     0     0    3.50000    0  351          -    3.50000      -     -   19s\n",
      "     0     0    3.50000    0  484          -    3.50000      -     -   20s\n",
      "     0     0    3.50000    0  319          -    3.50000      -     -   28s\n",
      "     0     0    3.50000    0  415          -    3.50000      -     -   29s\n",
      "     0     0    3.50000    0  189          -    3.50000      -     -   33s\n",
      "     0     0    3.50000    0  337          -    3.50000      -     -   33s\n",
      "     0     0    3.50000    0  257          -    3.50000      -     -   38s\n",
      "H    0     0                     245.8887588    3.50000  98.6%     -   38s\n",
      "H    0     0                     244.1323185    3.50000  98.6%     -   38s\n",
      "H    0     0                     145.7716628    3.50000  97.6%     -   38s\n",
      "H    0     0                      73.7576112    3.50000  95.3%     -   38s\n",
      "H    0     0                      70.2447307    3.50000  95.0%     -   38s\n",
      "     0     0    3.50000    0  352   70.24473    3.50000  95.0%     -   38s\n",
      "     0     0    3.50000    0  177   70.24473    3.50000  95.0%     -   43s\n",
      "H    0     0                      56.1932084    3.50000  93.8%     -   43s\n",
      "H    0     0                      42.1416862    3.50000  91.7%     -   43s\n",
      "H    0     0                      28.0901639    3.50000  87.5%     -   43s\n",
      "H    0     0                      26.3337237    3.50000  86.7%     -   43s\n",
      "     0     0    3.50000    0    2   26.33372    3.50000  86.7%     -   47s\n",
      "H    0     0                       3.5000000    3.50000  0.00%     -   47s\n",
      "     0     0    3.50000    0    2    3.50000    3.50000  0.00%     -   47s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 673\n",
      "  MIR: 63\n",
      "  StrongCG: 3\n",
      "  GUB cover: 1083\n",
      "  Zero half: 1\n",
      "\n",
      "Explored 1 nodes (53130 simplex iterations) in 47.80 seconds (66.62 work units)\n",
      "Thread count was 22 (of 22 available processors)\n",
      "\n",
      "Solution count 10: 3.5 26.3337 28.0902 ... 245.889\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.500000000000e+00, best bound 3.500000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "m.Params.timelimit = 600\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in TB:\n",
    "    tmp4 = m.getVarByName('d' + '[' + str(i) + ']')\n",
    "print(tmp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Tree Structure (OCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tree Structure: \n",
    "\n",
    "Variables a, b, z, N_k and c=argmax{N_kt} are the decisive variables for the tree structure.\n",
    "\n",
    "Take a point x_i, if <a_1,x_i> <= b_1, then x_i is down to node 2, otherwise down to node 3;\n",
    "suppose x_i gets to node 2, then if <a_2,x_i> <= b_2, then x_i will be in node 4, otherwise node 5.\n",
    "\n",
    "Such process continues until x_i reaches a leaf node.\n",
    "\n",
    "For each leaf node t, we then count the number of points in each class k, which is N_kt.\n",
    "\n",
    "max{N_kt} represents the most popular class, which is c_t, in leaf node t, but not every point in \n",
    "such leaf is of class c_t.\n",
    "\n",
    "If L_t = 0, then every point in leaf node t is indeed of class c_t, and the tree is pure. \n",
    "\n",
    "So L_t is the number of misclassified points in leaf node t.\n",
    "\n",
    "Since every point can only be in one of the leaf nodes, the sum of L_t is the total number of\n",
    "misclassified points in the tree.\n",
    "\n",
    "For a testing set, we create a tree with the splitting criterion based on a and b; then N_kt and L_t are what\n",
    "need to be calculated to access the accuracy of the tree on the testing set. The number of splits in each level\n",
    "of the testing tree is then number of observations times the number of branch nodes. \n",
    "\n",
    "The problem is then how to perform the splits efficiently? \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0.  1. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0.  1. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0.  1.]\n",
      " [-0.  1. -0.  1. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.  1. -0.]] [0.42508449 0.33966245 0.58776865 0.30678622 0.56505417 0.45876304\n",
      " 0.80144225] [1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a_matrix = np.zeros((p, len(TB)))\n",
    "threshold_oct = np.zeros(len(TB))\n",
    "split_position = np.zeros(len(TB))\n",
    "\n",
    "for i in TB:\n",
    "    split_position[i-1] = d[i].X\n",
    "\n",
    "for i in TB:\n",
    "    threshold_oct[i-1] = b[i].X\n",
    "    \n",
    "for i in range(p):\n",
    "    for t_idx, t in enumerate(TB):  # convert TB to indexable order\n",
    "        a_matrix[i, t_idx] = a[i, t].X\n",
    "\n",
    "print(a_matrix, threshold_oct,split_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the coefficients of a and b\n",
    "coff_a = np.zeros([p, len(TB)], dtype = int) \n",
    "coff_b = np.zeros(len(TB))\n",
    "\n",
    "for i in TB:\n",
    "    tmp1 = m.getVarByName('b_t[' + str(i) + ']')\n",
    "    coff_b[i-1] = tmp1.X  #i-1 due to TB is [1, 2, 3, 4, 5, 6, 7] (make sure it is not out of range)\n",
    "\n",
    "    for j in range(p):\n",
    "        tmp2 = m.getVarByName('a_t[' + str(j) + ',' + str(i) + ']')\n",
    "        coff_a[j, i-1] = int(tmp2.X)\n",
    "\n",
    "# Obtain the labels of leaf nodes\n",
    "labels = np.zeros(len(TL), dtype = int) - 1\n",
    "coff_c = np.zeros([K, len(TL)], dtype = int)\n",
    "\n",
    "for i in range(K):\n",
    "    for j_idx, j in enumerate(TL): #Note TL is [8, 9, 10, 11, 12, 13, 14, 15] reset the index to [0,1,2,3,4,5,6,7]\n",
    "        tmp3 = m.getVarByName('c_kt[' + str(i) + ',' + str(j) + ']')\n",
    "        coff_c[i, j_idx] = int(tmp3.X)\n",
    "\n",
    "k_idx, t_idx = np.where(coff_c == 1)\n",
    "\n",
    "for i in range(len(k_idx)):\n",
    "    labels[t_idx[i]] = k_idx[i]            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coff_a: [[0 1 0 1 1 1 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "coff_b: [0.67287182 0.49712215 0.7343464  0.30153485 0.62587934 0.74078022\n",
      " 0.61421259]\n",
      "coff_c: [[0 0 0 1 1 1 1 1]\n",
      " [1 1 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"coff_a: \" + str(coff_a))\n",
    "print(\"coff_b: \" + str(coff_b))\n",
    "print(\"coff_c: \" + str(coff_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCT-H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_h = gp.Model('OCT-H')\n",
    "mu = 0.005  #Base on the paper mu is a sufficiently small constant\n",
    "alpha = 0.5\n",
    "#M = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables: Introduce s and a_hat as New Variables for OCT-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m_h.addVars(p,TB, vtype=GRB.BINARY, name=\"a_t\") #dim px|TB|\n",
    "a_hat = m_h.addVars(p, TB, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=\"a_hat\") #dim px|TB|\n",
    "b = m_h.addVars(TB, vtype=GRB.CONTINUOUS, lb = 0, ub = 1, name=\"b_t\") #dim |TB|\n",
    "d = m_h.addVars(TB, vtype=GRB.BINARY, name=\"d_t\") #dim |TB|\n",
    "s = m_h.addVars(p,TB, vtype=GRB.BINARY, name=\"s\") #dim px|TB|\n",
    "z = m_h.addVars(n, TL, vtype=GRB.BINARY, name=\"z\") #dim nx|TL|\n",
    "l = m_h.addVars(TL, vtype=GRB.BINARY, name=\"l_t\") #dim |TL|\n",
    "Nk = m_h.addVars(K, TL, vtype=GRB.INTEGER,name=\"N_kt\") #dim Kx|TL|\n",
    "N = m_h.addVars(TL, vtype=GRB.INTEGER, name=\"N_t\") #dim |TL|\n",
    "ck = m_h.addVars(K, TL, vtype=GRB.BINARY, name=\"c_kt\")\n",
    "L = m_h.addVars(TL, name=\"L_t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm start using the results of CART algorithm\n",
    "for i in TB:\n",
    "    a[feature_indices[i-1], i].start = 1\n",
    "    b[i].start = threshold_indices[i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Constraints (OCT-H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in TB:\n",
    "    m_h.addConstr(d[t] == 1, name=\"dt_constraint_d(t)\") \n",
    "    m_h.addConstr(b[t] <= d[t], name=\"bt_constraint1_dt\")     # bt <= dt\n",
    "    m_h.addConstr(-d[t] <= b[t], name=\"bt_constraint2_dt\")    #-dt <= bt\n",
    "    \n",
    "    m_h.addConstr(s.sum(\"*\",t) >= d[t], name=\"sum_constraint_of_sjt\")  #sum of sjt >= dt\n",
    "    for i in range(p):\n",
    "        m_h.addConstr(s[i,t] <= d[t], name=\"s_constraint1_dt\")     # sjt <= dt\n",
    "        m_h.addConstr(-s[i,t] <= a[i,t], name=\"a_constraint1_-st\")  # -sjt <= ajt\n",
    "        m_h.addConstr(a[i,t] <= s[i,t], name=\"a_constraint2_st\")   # ajt <= sjt  \n",
    "\n",
    "    m_h.addConstr(a_hat.sum(\"*\",t) <= d[t], name=\"sum_constraint_of_a_hat\") #sum of a_hat_jt >= dt\n",
    "    for i in range(p):\n",
    "        m_h.addConstr(a_hat[i,t] >= -a[i,t], name=\"a_hat_constraint_-a\") #a_hat >= -ajt \n",
    "        m_h.addConstr(a_hat[i,t] >= a[i,t], name=\"a_hat_constraint_a\")   #a_hat >= ajt  \n",
    "\n",
    "for t in TB[1:]:\n",
    "    m_h.addConstr(d[t] <= d[t//2], name=\"dt_constraint_dp(t)\") # dt <= dp(t)   \n",
    "\n",
    "for t in TL:\n",
    "    m_h.addConstr(z.sum(\"*\",t) >= N_min*l[t], name=\"sum_of_zt_constraint_Nmin_lt\") # sum of zit >= Nmin*lt\n",
    "    m_h.addConstr(z.sum(i,\"*\") == 1, name=\"sum_of_zi(t)_constraint_1\")  # sum sum of zit = 1\n",
    "    \n",
    "    for i in range(n):\n",
    "        m_h.addConstr(z[i, t] <= l[t]) # zit <= lt\n",
    "  \n",
    "    for k in range(K):\n",
    "        m_h.addConstr(Nk[k,t] == 1/2 * gp.quicksum(z[i,t] * (Y[i,k] + 1) for i in range(n))) #Nkt = 1/2(sum of (1+Yik)*zit #may need to be corrected\n",
    "\n",
    "    m_h.addConstr(N[t] == z.sum(\"*\",t))  # Nt = sum of zit\n",
    "    m_h.addConstr(l[t] == ck.sum(\"*\",t)) # sum of ckt = lt\n",
    "    m_h.addConstr(l[t] == 1, name=\"dt_constraint_l(t)\")\n",
    " \n",
    "for t in TL:\n",
    "    l_ancestors = left_ancestors[t - 1]  # cache the list\n",
    "    if l_ancestors:\n",
    "        for la in l_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X.iloc[i]  # cache row once\n",
    "                m_h.addConstr(gp.quicksum(a[j,la]*xi[j] for j in range(p))+mu <= b[la]+(2+mu)*(1-z[i, t]),\n",
    "                    name=f\"split_l_{la}_{i}_{t}\"\n",
    "                )\n",
    "                \n",
    "    r_ancestors = right_ancestors[t - 1]\n",
    "    if r_ancestors:\n",
    "        for ra in r_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X.iloc[i]  # cache the row once\n",
    "                m_h.addConstr(\n",
    "                    gp.quicksum(a[j, ra]*xi[j] for j in range(p)) >= b[ra]-2*(1-z[i, t]),\n",
    "                    name=f\"split_r_{ra}_{i}_{t}\"\n",
    "                )\n",
    "         \n",
    "for t in TL:\n",
    "    m_h.addConstr(L[t] >= 0, name=\"Lt_constraint3\") #Lt ≥ 0\n",
    "    for k in range(K):\n",
    "        m_h.addConstr(L[t] >= N[t] - Nk[k,t] - n*(1-ck[k,t]), name=\"Lt_constraint1\") #Lt ≤ Nt − Nkt + n(1-ckt) \n",
    "        m_h.addConstr(L[t] <= N[t] - Nk[k,t] + n*ck[k,t], name=\"Lt_constraint2\")  #Lt ≤ Nt − Nkt + n*ckt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective OCT-H and Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 600\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) Ultra 9 185H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 22 logical processors, using up to 22 threads\n",
      "\n",
      "Optimize a model with 96382 rows, 24217 columns and 768745 nonzeros\n",
      "Model fingerprint: 0xff54e03e\n",
      "Variable types: 64 continuous, 24153 integer (24129 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 3e+03]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "\n",
      "Warning: Completing partial solution with 24146 unfixed non-continuous variables out of 24153\n",
      "User MIP start did not produce a new incumbent solution\n",
      "\n",
      "Presolve removed 24269 rows and 80 columns\n",
      "Presolve time: 1.06s\n",
      "Presolved: 72113 rows, 24137 columns, 672180 nonzeros\n",
      "Variable types: 7 continuous, 24130 integer (24106 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal simplex, dual simplex, and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Root barrier log...\n",
      "\n",
      "Ordering time: 0.10s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 56\n",
      " AA' NZ     : 7.201e+05\n",
      " Factor NZ  : 1.947e+06 (roughly 60 MB of memory)\n",
      " Factor Ops : 5.266e+07 (less than 1 second per iteration)\n",
      " Threads    : 13\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   1.71397544e+04 -1.31361640e+06  9.72e+02 6.35e+00  2.21e+02     2s\n",
      "   1   1.10418576e+04 -2.70466972e+06  6.86e+02 4.55e-01  1.36e+02     2s\n",
      "   2   1.39587498e+03 -1.48916266e+06  1.93e+01 7.00e-10  1.50e+01     3s\n",
      "   3   2.26187273e+01 -4.27056782e+05  2.26e-02 1.81e-10  3.60e+00     3s\n",
      "   4   1.53514742e+01 -7.97199368e+03  8.61e-12 3.01e-10  6.72e-02     3s\n",
      "   5   3.71631126e+00 -1.28469156e+03  5.22e-12 3.49e-11  1.08e-02     3s\n",
      "   6   4.78839892e+00 -8.40204922e+02  2.16e-12 2.32e-11  7.09e-03     3s\n",
      "   7   3.52398626e+00 -4.83977228e+01  4.29e-12 4.05e-13  4.34e-04     3s\n",
      "   8   3.50121705e+00  3.44771535e+00  3.00e-12 4.33e-14  4.44e-07     3s\n",
      "   9   3.50000122e+00  3.49994772e+00  5.14e-12 1.55e-14  4.44e-10     3s\n",
      "  10   3.50000000e+00  3.49999995e+00  1.11e-12 4.53e-15  4.44e-13     3s\n",
      "  11   3.50000000e+00  3.50000000e+00  2.42e-13 7.11e-15  7.80e-19     3s\n",
      "\n",
      "Barrier solved model in 11 iterations and 3.02 seconds (2.46 work units)\n",
      "Optimal objective 3.50000000e+00\n",
      "\n",
      "Concurrent spin time: 0.54s (can be avoided by choosing Method=3)\n",
      "\n",
      "Solved with barrier\n",
      "\n",
      "Root relaxation: objective 3.500000e+00, 24051 iterations, 1.61 seconds (0.79 work units)\n",
      "Total elapsed time = 6.47s (DegenMoves)\n",
      "Total elapsed time = 10.08s (DegenMoves)\n",
      "Total elapsed time = 15.51s (DegenMoves)\n",
      "Another try with MIP start\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    3.50000    0  749          -    3.50000      -     -   20s\n",
      "     0     0    3.50000    0  812          -    3.50000      -     -   27s\n",
      "     0     0    3.50000    0  816          -    3.50000      -     -   28s\n",
      "     0     0    3.50000    0  652          -    3.50000      -     -   34s\n",
      "     0     0    3.50000    0  863          -    3.50000      -     -   34s\n",
      "     0     0    3.50000    0  480          -    3.50000      -     -   41s\n",
      "     0     0    3.50000    0  501          -    3.50000      -     -   42s\n",
      "     0     0    3.50000    0  364          -    3.50000      -     -   47s\n",
      "     0     0    3.50000    0  412          -    3.50000      -     -   47s\n",
      "     0     0    3.50000    0  476          -    3.50000      -     -   54s\n",
      "     0     0    3.50000    0  541          -    3.50000      -     -   55s\n",
      "     0     0    3.50000    0  441          -    3.50000      -     -   69s\n",
      "     0     0    3.50000    0  555          -    3.50000      -     -   69s\n",
      "     0     0    3.50000    0   33          -    3.50000      -     -   72s\n",
      "H    0     0                      49.1674473    3.50000  92.9%     -   72s\n",
      "H    0     0                      43.8981265    3.50000  92.0%     -   73s\n",
      "     0     0    3.50000    0  331   43.89813    3.50000  92.0%     -   73s\n",
      "     0     0    3.50000    0    2   43.89813    3.50000  92.0%     -   84s\n",
      "H    0     0                       3.5000000    3.50000  0.00%     -   84s\n",
      "     0     0    3.50000    0    2    3.50000    3.50000  0.00%     -   84s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 297\n",
      "  MIR: 20\n",
      "  StrongCG: 225\n",
      "  GUB cover: 26\n",
      "\n",
      "Explored 1 nodes (110717 simplex iterations) in 84.88 seconds (126.41 work units)\n",
      "Thread count was 22 (of 22 available processors)\n",
      "\n",
      "Solution count 3: 3.5 43.8981 49.1674 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.500000000000e+00, best bound 3.500000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "m_h.update()\n",
    "m_h.setObjective(L.sum('*') / L_hat + alpha*gp.quicksum(gp.quicksum(s[i,t] for i in range(p)) for t in TB), GRB.MINIMIZE) #minimize m_h.setObjective(gp.quicksum(L[t]/L_hat for t in TL) + alpha*gp.quicksum(gp.quicksum(s[i,t] for i in range(p)) for t in TB), GRB.MINIMIZE) L + alpha*sum(sum(sjt)) for j in p, t in TB\n",
    "m.Params.timelimit = 600\n",
    "m_h.optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
