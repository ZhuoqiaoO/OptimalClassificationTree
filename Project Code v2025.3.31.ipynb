{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "from gurobipy import *\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from ucimlrepo import fetch_ucirepo as fetc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data and Check Data Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Area               500 non-null    float64\n",
      " 1   Perimeter          500 non-null    float64\n",
      " 2   Major_Axis_Length  500 non-null    float64\n",
      " 3   Minor_Axis_Length  500 non-null    float64\n",
      " 4   Eccentricity       500 non-null    float64\n",
      " 5   Convex_Area        500 non-null    float64\n",
      " 6   Extent             500 non-null    float64\n",
      " 7   target             500 non-null    int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 31.4 KB\n",
      "       Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
      "0  0.662065   0.813361           0.861783           0.436630      0.956316   \n",
      "1  0.590547   0.558154           0.484146           0.603196      0.606234   \n",
      "2  0.587811   0.613745           0.612838           0.503749      0.781009   \n",
      "3  0.406468   0.264585           0.282313           0.495721      0.569173   \n",
      "4  0.594527   0.663084           0.575227           0.542501      0.724255   \n",
      "\n",
      "   Convex_Area    Extent  target  \n",
      "0     0.666749  0.176442       0  \n",
      "1     0.599606  0.298026       0  \n",
      "2     0.585068  0.520446       0  \n",
      "3     0.389676  0.370142       0  \n",
      "4     0.623013  0.385446       0  \n"
     ]
    }
   ],
   "source": [
    "rice = fetc(id=545)\n",
    "X = rice.data.features \n",
    "y = rice.data.targets\n",
    "df = pd.DataFrame(X, columns=rice.data.feature_names)[:500]\n",
    "df['target'] = y\n",
    "\n",
    "#Change non numeric columns to numeric\n",
    "column_names = [\"Area\", \"Perimeter\", \"Major_Axis_Length\", \"Minor_Axis_Length\",\"Eccentricity\", \"Convex_Area\", \"Extent\", \"target\"]\n",
    "non_numeric_cols = df.drop(['target'],axis=1).select_dtypes(exclude=[np.number]).columns\n",
    "if not non_numeric_cols.empty:\n",
    "    for col in non_numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = StandardScaler().fit_transform(df[[col]])\n",
    "    \n",
    "for col in column_names[:len(column_names)-1]:\n",
    "    df[col] = MinMaxScaler().fit_transform(df[[col]])\n",
    "\n",
    "#Convert target column to numeric\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['target'])\n",
    "        \n",
    "df.info()\n",
    "#df.isnull().sum()\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Class: 1 which are: [0]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "print(\"Total number of Class: \" + str(len(np.unique(y))) + \" which are: \" + str(np.unique(y)))\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy Score:  1.0 Training Set Accuracy Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "def clf(x_train, y_train, x_test, y_test,K):\n",
    "    clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=K, random_state=42)\n",
    "    clf_gini.fit(x_train, y_train)\n",
    "    y_pred_gini = clf_gini.predict(x_test)\n",
    "    y_pred_gini_train = clf_gini.predict(x_train)\n",
    "    print('Testing Set Accuracy Score: ', accuracy_score(y_test, y_pred_gini), 'Training Set Accuracy Score:',accuracy_score(y_train, y_pred_gini_train))\n",
    "\n",
    "clf(x_train, y_train, x_test, y_test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Structure: Will be Used for Warmstart of OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Indices:  [] Threshold Indices: []\n",
      "1\n",
      "Internal nodes: 0, Total nodes: 1\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "\"\"\"\n",
    "The following is for warm start in OCT\n",
    "\"\"\"\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "feature_indices = []\n",
    "threshold_indices = []\n",
    "feature_indices_leaf =[]\n",
    "threshold_indices_leaf = []\n",
    "for i in range(len(feature)):\n",
    "    if feature[i] != -2 and feature[i+1] != -2:\n",
    "        feature_indices.append(int(feature[i]))\n",
    "        threshold_indices.append(float(threshold[i]))\n",
    "    elif feature[i] != -2 and feature[i+1] == -2:\n",
    "        feature_indices_leaf.append(int(feature[i]))\n",
    "        threshold_indices_leaf.append(float(threshold[i]))\n",
    "    else:\n",
    "        continue\n",
    "feature_indices.extend(feature_indices_leaf)\n",
    "threshold_indices.extend(threshold_indices_leaf)\n",
    "print(\"Feature Indices: \", feature_indices, \"Threshold Indices:\", threshold_indices)\n",
    "#leaf nodes\n",
    "#branch nodes\n",
    "print(np.sum(clf.tree_.feature == -2))\n",
    "internal_nodes = np.sum(clf.tree_.feature != -2)\n",
    "total_nodes = clf.tree_.node_count\n",
    "print(f\"Internal nodes: {internal_nodes}, Total nodes: {total_nodes}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf nodes: 0, Branch nodes: 0\n"
     ]
    }
   ],
   "source": [
    "total_nodes = clf.tree_.node_count\n",
    "leaf_nodes = round(total_nodes / 2)\n",
    "branch_nodes = total_nodes // 2\n",
    "print(f\"Leaf nodes: {leaf_nodes}, Branch nodes: {branch_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCT Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2643923\n",
      "Academic license - for non-commercial use only - expires 2026-03-28\n"
     ]
    }
   ],
   "source": [
    "m = gp.Model('OCT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraining data (X,Y)=(x_i,y_i), i=1,...,n; x_i in R^p and normalized to [0,1]^p, y_i in {1,...,K}\\n-n = # obervations\\n-p = # features\\n-K = # class label\\n\\n-p(t) = parent nodes of node t\\n-A_L(t) = {left_branch ancestors of t} = {t if tmod2=0 and t/2 recursively gives the set}\\n-A_R(t) = {right_branch ancestors of t} = {t if (t-1)mod2=0 and (t-1)/2 recursively gives the set}\\n\\n\\n-D = max depth\\n-T = 2^(D+1)-1 = max # nodes\\n-TB = branch nodes = left nodes = {1,...,floor(T/2)} applies split is ax<b \\n-TL = leaf = {floor(T/2)+1,...,T} make class prediction\\n-?a_t in R^p\\n-?b_t in R\\n-p = # features\\n\\n-d_t = 1{node t applies a split}\\n-sum a_jt = d_t, j=1,...p, t in TB\\n-0 <= b_t <= d_t, t in TB\\n-a_jt in {0,1}, j=1,...p, t in TB\\n\\n\\n-d_t <= d_p(t), t in TB/{1}\\n\\n-z_it = 1{x_i in node t}\\n-l_t = 1{leaf t contains any point}\\n-z_it <= l_t, t in TB\\n-sum(z_it) >= N_min*l_t for i=1,...,n, t in TB\\n-sum(z_it)=1 for t in TB, i=1,...,n\\n\\n-x_j^i = ith largest value in feature j\\n-epsilon_j = min{x_j^(i+1)-x_j^i, i=1,...,n}\\n-epsilon_max = max{epsilon_j} wrt j\\n-epsilon  = {epsilon_1,...,epsilon_p}\\n-a_m(x_t + epsilon) <= b_m +(1+epsilon_max)(1-z_it), i=1,...,n, for all t in TB, for all m in A_L(t)\\n-a_m*x_i >= b_m - (1-z_it), i=1,...,n, for all t in TB, for all m in A_R(t)\\n\\n-Y_ik = {1 if y_i=k, -1 otherwise}, k=1,...,K, i=1,...n\\nN_kt = 0.5*sum((1+Y_ik)z_it) for i=1,...,n; k=1,...K, t in TL\\nN_t = sum(z_it) for i=1,...,n; t in TL\\nc_t = argmax{N_kt} wrt k\\nc_kt = 1{c_t = k}\\nsum(c_kt) = l_t wrt k\\n\\nL_t = N_t - max{N_kt} wrt k = min{N_t - N_kt} wrt k\\nL_t >= N_t - N_kt - n(1-c_kt), k=1,...K, t in TL\\nL_t <= N_t - N_kt + n*c_kt, k=1,...K, t in TL\\nL_t >= 0\\n\\nL^ = baseline accuracy = #{most popular class}/n\\n\\nobjective: min (1/L^)sum(L_t) for t in TL + alpha*sum(d_t) for t in TB\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "training data (X,Y)=(x_i,y_i), i=1,...,n; x_i in R^p and normalized to [0,1]^p, y_i in {1,...,K}\n",
    "-n = # obervations\n",
    "-p = # features\n",
    "-K = # class label\n",
    "\n",
    "-p(t) = parent nodes of node t\n",
    "-A_L(t) = {left_branch ancestors of t} = {t if tmod2=0 and t/2 recursively gives the set}\n",
    "-A_R(t) = {right_branch ancestors of t} = {t if (t-1)mod2=0 and (t-1)/2 recursively gives the set}\n",
    "\n",
    "\n",
    "-D = max depth\n",
    "-T = 2^(D+1)-1 = max # nodes\n",
    "-TB = branch nodes = left nodes = {1,...,floor(T/2)} applies split is ax<b \n",
    "-TL = leaf = {floor(T/2)+1,...,T} make class prediction\n",
    "-?a_t in R^p\n",
    "-?b_t in R\n",
    "-p = # features\n",
    "\n",
    "-d_t = 1{node t applies a split}\n",
    "-sum a_jt = d_t, j=1,...p, t in TB\n",
    "-0 <= b_t <= d_t, t in TB\n",
    "-a_jt in {0,1}, j=1,...p, t in TB\n",
    "\n",
    "\n",
    "-d_t <= d_p(t), t in TB/{1}\n",
    "\n",
    "-z_it = 1{x_i in node t}\n",
    "-l_t = 1{leaf t contains any point}\n",
    "-z_it <= l_t, t in TB\n",
    "-sum(z_it) >= N_min*l_t for i=1,...,n, t in TB\n",
    "-sum(z_it)=1 for t in TB, i=1,...,n\n",
    "\n",
    "-x_j^i = ith largest value in feature j\n",
    "-epsilon_j = min{x_j^(i+1)-x_j^i, i=1,...,n}\n",
    "-epsilon_max = max{epsilon_j} wrt j\n",
    "-epsilon  = {epsilon_1,...,epsilon_p}\n",
    "-a_m(x_t + epsilon) <= b_m +(1+epsilon_max)(1-z_it), i=1,...,n, for all t in TB, for all m in A_L(t)\n",
    "-a_m*x_i >= b_m - (1-z_it), i=1,...,n, for all t in TB, for all m in A_R(t)\n",
    "\n",
    "-Y_ik = {1 if y_i=k, -1 otherwise}, k=1,...,K, i=1,...n\n",
    "N_kt = 0.5*sum((1+Y_ik)z_it) for i=1,...,n; k=1,...K, t in TL\n",
    "N_t = sum(z_it) for i=1,...,n; t in TL\n",
    "c_t = argmax{N_kt} wrt k\n",
    "c_kt = 1{c_t = k}\n",
    "sum(c_kt) = l_t wrt k\n",
    "\n",
    "L_t = N_t - max{N_kt} wrt k = min{N_t - N_kt} wrt k\n",
    "L_t >= N_t - N_kt - n(1-c_kt), k=1,...K, t in TL\n",
    "L_t <= N_t - N_kt + n*c_kt, k=1,...K, t in TL\n",
    "L_t >= 0\n",
    "\n",
    "L^ = baseline accuracy = #{most popular class}/n\n",
    "\n",
    "objective: min (1/L^)sum(L_t) for t in TL + alpha*sum(d_t) for t in TB\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predetermined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: [0.0001243781094526497, 7.970128041545621e-06, 3.1573452483613096e-06, 1.3403733430950027e-06, 6.274424829699754e-07, 0.0001231982259455311, 4.938707722224045e-06]\n",
      "epsilon_max: 0.0001243781094526497\n",
      "Yik: [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "n= df.shape[0] # number of observations\n",
    "p = df.drop(['target'],axis=1).shape[1] # number of features\n",
    "K = len(np.unique(df['target'])) # number of classes\n",
    "D = 3 # max depth\n",
    "T = 2**(D+1)-1 # max number of nodes\n",
    "L_hat = df['target'].value_counts().max()/n # baseline accuracy\n",
    "\n",
    "N_min = math.floor(n*0.05)\n",
    "\n",
    "#Epsilon\n",
    "epsilon=[]\n",
    "for j in range(p):\n",
    "    x_j = df.iloc[:,j].tolist()\n",
    "    x_j.sort()  \n",
    "    e=[]\n",
    "    for i in range(n-1):\n",
    "        if x_j[i+1]!=x_j[i]:\n",
    "            e.append(x_j[i+1] - x_j[i])\n",
    "    epsilon.append(min(e))\n",
    "epsilon_max = max(epsilon)\n",
    "\n",
    "print(\"epsilon: \" + str(epsilon))\n",
    "print(\"epsilon_max: \" + str(epsilon_max))\n",
    "\n",
    "\n",
    "#Y Matrix\n",
    "Y = np.zeros([n,K], dtype = int) - 1 # Y_ik\n",
    "Y[df.index,  y] = 1  #based on the sample code, the [x,y] x is the features index, y is the class index\n",
    "print(\"Yik: \" + str(Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predetermined Sets (Note that index starts from 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7]\n",
      "Branch nodes:  [1, 2, 3, 4, 5, 6, 7]\n",
      "Leaf nodes:  [8, 9, 10, 11, 12, 13, 14, 15]\n",
      "left_ancestors: [[], [1], [], [1, 2], [1], [3], [], [1, 2, 4], [1, 2], [1, 5], [1], [3, 6], [3], [7], []]\n",
      "right_ancestors: [[], [], [1], [], [2], [1], [1, 3], [], [4], [2], [2, 5], [1], [1, 6], [1, 3], [1, 3, 7]]\n"
     ]
    }
   ],
   "source": [
    "parent = []\n",
    "for t in range(1,T+1):\n",
    "    if t%2==0:\n",
    "        parent.append(t//2)\n",
    "    else:\n",
    "        parent.append((t-1)//2)\n",
    "print(parent)\n",
    "\n",
    "left_ancestors = []\n",
    "right_ancestors = []\n",
    "for t in range(1,T+1):\n",
    "    la_t =[]\n",
    "    ra_t =[]\n",
    "    tau=t\n",
    "    while tau>1:\n",
    "        pt = tau//2\n",
    "        if tau % 2 == 0: #if t is even, then its parent is a left ancestor, else is a right ancestor\n",
    "            la_t.append(pt)\n",
    "        else:\n",
    "            ra_t.append(pt)\n",
    "        tau = pt\n",
    "    la_t.sort() \n",
    "    ra_t.sort()\n",
    "    left_ancestors.append(la_t)\n",
    "    right_ancestors.append(ra_t)\n",
    "\n",
    "TB = list(range(1,math.floor((T+1)/2)))  #Branch nodes\n",
    "TL = list(range(math.floor((T+1)/2),T+1)) #Leaf nodes\n",
    "TT = list(range(1,T+1)) #total nodes\n",
    "\n",
    "print(\"Branch nodes: \", TB)\n",
    "print(\"Leaf nodes: \", TL)\n",
    "\n",
    "print(\"left_ancestors: \" + str(left_ancestors))\n",
    "print(\"right_ancestors: \" + str(right_ancestors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m.addVars(p,TB, vtype=GRB.BINARY, name=\"a_t\") #dim |TB|xp\n",
    "b = m.addVars(TB, vtype=GRB.CONTINUOUS, lb = 0, ub = 1, name=\"b_t\") #dim |TB|\n",
    "d = m.addVars(TB, vtype=GRB.BINARY, name=\"d_t\") #dim |TB|\n",
    "z = m.addVars(n, TL, vtype=GRB.BINARY, name=\"z\") #dim nx|TL|\n",
    "l = m.addVars(TL, vtype=GRB.BINARY, name=\"l_t\") #dim |TL|\n",
    "Nk = m.addVars(K, TL, vtype=GRB.INTEGER,name=\"N_kt\") #dim Kx|TL|\n",
    "N = m.addVars(TL, vtype=GRB.INTEGER, name=\"N_t\") #dim |TL|\n",
    "ck = m.addVars(K, TL, vtype=GRB.BINARY, name=\"c_kt\")\n",
    "L = m.addVars(TL, name=\"L_t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# warm start using the results of CART algorithm\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m TB:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     a[\u001b[43mfeature_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m, i].start = \u001b[32m1\u001b[39m\n\u001b[32m      4\u001b[39m     b[i].start = threshold_indices[i-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# warm start using the results of CART algorithm\n",
    "for i in TB:\n",
    "    a[feature_indices[i-1], i].start = 1\n",
    "    b[i].start = threshold_indices[i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in TB:\n",
    "    m.addConstr(a.sum(\"*\",t) == d[t], name=\"sum_constraint_of_ajt\") # sum of ajt = dt\n",
    "    m.addConstr(b[t] <= d[t], name=\"bt_constraint_dt\")     # bt <= dt\n",
    "    m.addConstr(d[t] == 1, name=\"dt_constraint_d(t)\") \n",
    "\n",
    "for t in TB[1:]:\n",
    "    m.addConstr(d[t] <= d[t//2], name=\"dt_constraint_dp(t)\") # dt <= dp(t)    \n",
    "\n",
    "for t in TL:\n",
    "    for i in range(n):\n",
    "        m.addConstr(z[i, t] <= l[t]) # zit <= lt\n",
    "    \n",
    "    m.addConstr(z.sum(\"*\",t) >= N_min*l[t], name=\"sum_of_zt_constraint_Nmin_lt\") # sum of zit >= Nmin*lt\n",
    "    \n",
    "    m.addConstr(z.sum(i,\"*\") == 1, name=\"sum_of_zi(t)_constraint_1\")  # sum sum of zit = 1\n",
    "    \n",
    "    for k in range(K):\n",
    "        m.addConstr(Nk[k,t] == 1/2 * gp.quicksum(z[i,t] * (Y[i,k] + 1) for i in range(n))) #Nkt = 1/2(sum of (1+Yik)*zit #may need to be corrected\n",
    "\n",
    "    m.addConstr(N[t] == z.sum(\"*\",t))  # Nt = sum of zit\n",
    "\n",
    "    m.addConstr(l[t] == ck.sum(\"*\",t)) # sum of ckt = lt\n",
    "    \n",
    "    m.addConstr(l[t] == 1, name=\"dt_constraint_l(t)\")\n",
    "    \n",
    "for t in TL:\n",
    "    l_ancestors = left_ancestors[t - 1]  # cache the list\n",
    "    if l_ancestors:\n",
    "        for la in l_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X.iloc[i]  # cache row once\n",
    "                m.addConstr(gp.quicksum(a[j, la] * (xi[j] + epsilon[j]) for j in range(p)) <= b[la] + (1 + epsilon_max) * (1 - z[i, t]),\n",
    "                    name=f\"split_l_{la}_{i}_{t}\"\n",
    "                )\n",
    "                \n",
    "    r_ancestors = right_ancestors[t - 1]\n",
    "    if r_ancestors:\n",
    "        for r in r_ancestors:\n",
    "            for i in range(n):\n",
    "                xi = X.iloc[i]  # cache the row once\n",
    "                m.addConstr(\n",
    "                    gp.quicksum(a[j, r] * xi[j] for j in range(p)) >= b[r] - (1 - z[i, t]),\n",
    "                    name=f\"split_r_{r}_{i}_{t}\"\n",
    "                )\n",
    "        \n",
    "for t in TL:\n",
    "    for k in range(K):\n",
    "        m.addConstr(L[t] >= N[t] - Nk[k,t] - n*(1-ck[k,t]), name=\"Lt_constraint1\") #Lt ≤ Nt − Nkt + n(1-ckt) \n",
    "        m.addConstr(L[t] <= N[t] - Nk[k,t] + n*ck[k,t], name=\"Lt_constraint2\")  #Lt ≤ Nt − Nkt + n*ckt \n",
    "    m.addConstr(L[t] >= 0, name=\"Lt_constraint3\") #Lt ≥ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update()\n",
    "m.setObjective(L.sum('*') / L_hat + 0.5*gp.quicksum(d[t] for t in TB), GRB.MINIMIZE) #minimize L + alpha*sum(d_t) for t in TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 600\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) Ultra 9 185H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 22 logical processors, using up to 22 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  600\n",
      "\n",
      "Optimize a model with 16099 rows, 4103 columns and 128189 nonzeros\n",
      "Model fingerprint: 0xd8d30f2a\n",
      "Variable types: 15 continuous, 4088 integer (4072 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [6e-07, 5e+02]\n",
      "  Objective range  [5e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+02]\n",
      "Presolve removed 4083 rows and 47 columns\n",
      "Presolve time: 0.20s\n",
      "Presolved: 12016 rows, 4056 columns, 111973 nonzeros\n",
      "Variable types: 7 continuous, 4049 integer (4049 binary)\n",
      "\n",
      "Root relaxation: objective 3.500000e+00, 530 iterations, 0.05 seconds (0.07 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    3.50000    0   28          -    3.50000      -     -    0s\n",
      "H    0     0                       3.5000000    3.50000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (1216 simplex iterations) in 0.67 seconds (0.62 work units)\n",
      "Thread count was 22 (of 22 available processors)\n",
      "\n",
      "Solution count 1: 3.5 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.500000000000e+00, best bound 3.500000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "m.Params.timelimit = 600\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of a[p, t]:\n",
      "a[0,1] = -0.0\n",
      "a[0,2] = -0.0\n",
      "a[0,3] = 1.0\n",
      "a[0,4] = -0.0\n",
      "a[0,5] = -0.0\n",
      "a[0,6] = 1.0\n",
      "a[0,7] = -0.0\n",
      "a[1,1] = 1.0\n",
      "a[1,2] = -0.0\n",
      "a[1,3] = -0.0\n",
      "a[1,4] = -0.0\n",
      "a[1,5] = -0.0\n",
      "a[1,6] = -0.0\n",
      "a[1,7] = -0.0\n",
      "a[2,1] = -0.0\n",
      "a[2,2] = -0.0\n",
      "a[2,3] = -0.0\n",
      "a[2,4] = -0.0\n",
      "a[2,5] = -0.0\n",
      "a[2,6] = -0.0\n",
      "a[2,7] = -0.0\n",
      "a[3,1] = -0.0\n",
      "a[3,2] = -0.0\n",
      "a[3,3] = -0.0\n",
      "a[3,4] = -0.0\n",
      "a[3,5] = 1.0\n",
      "a[3,6] = -0.0\n",
      "a[3,7] = -0.0\n",
      "a[4,1] = -0.0\n",
      "a[4,2] = -0.0\n",
      "a[4,3] = -0.0\n",
      "a[4,4] = -0.0\n",
      "a[4,5] = -0.0\n",
      "a[4,6] = -0.0\n",
      "a[4,7] = 1.0\n",
      "a[5,1] = -0.0\n",
      "a[5,2] = 1.0\n",
      "a[5,3] = -0.0\n",
      "a[5,4] = 1.0\n",
      "a[5,5] = -0.0\n",
      "a[5,6] = -0.0\n",
      "a[5,7] = -0.0\n",
      "a[6,1] = -0.0\n",
      "a[6,2] = -0.0\n",
      "a[6,3] = -0.0\n",
      "a[6,4] = -0.0\n",
      "a[6,5] = -0.0\n",
      "a[6,6] = -0.0\n",
      "a[6,7] = -0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Values of a[p, t]:\")\n",
    "for p_ in range(p):\n",
    "    for t in TB:\n",
    "        print(f\"a[{p_},{t}] = {a[p_, t].X}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of b[t]:\n",
      "b[1] = 0.5733511672123948\n",
      "b[2] = 0.5316003449550307\n",
      "b[3] = 0.6819651741293509\n",
      "b[4] = 0.4136996427251428\n",
      "b[5] = 0.6313206984543781\n",
      "b[6] = 0.5838308457711424\n",
      "b[7] = 0.7159684687146075\n"
     ]
    }
   ],
   "source": [
    "print(\"Values of b[t]:\")\n",
    "for t in TB:\n",
    "    print(f\"b[{t}] = {b[t].X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Tree Structure (OCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the coefficients of a and b\n",
    "coff_a = np.zeros([p, len(TB)], dtype = int) \n",
    "coff_b = np.zeros(len(TB))\n",
    "\n",
    "for i in TB:\n",
    "    tmp1 = m.getVarByName('b_t[' + str(i) + ']')\n",
    "    coff_b[i-1] = tmp1.X  #i-1 due to TB is [1, 2, 3, 4, 5, 6, 7] (make sure it is not out of range)\n",
    "        \n",
    "    for j in range(p):\n",
    "        tmp2 = m.getVarByName('a_t[' + str(j) + ',' + str(i) + ']')\n",
    "        coff_a[j, i-1] = int(tmp2.X)\n",
    "\n",
    "# Obtain the labels of leaf nodes\n",
    "labels = np.zeros(len(TL), dtype = int) - 1\n",
    "coff_ck = np.zeros([K, len(TL)], dtype = int)\n",
    "\n",
    "for i in range(K):\n",
    "    for j_idx, j in enumerate(TL): #Note TL is [8, 9, 10, 11, 12, 13, 14, 15] reset the index to [0,1,2,3,4,5,6,7]\n",
    "        tmp3 = m.getVarByName('c_kt[' + str(i) + ',' + str(j) + ']')\n",
    "        coff_ck[i, j_idx] = int(tmp3.X)\n",
    "\n",
    "k_idx, t_idx = np.where(coff_ck == 1)\n",
    "\n",
    "for i in range(len(k_idx)):\n",
    "    labels[t_idx[i]] = k_idx[i]            \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data (OCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCT-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_h = gp.Model('OCT-H')\n",
    "mu = 0.005  #Base on the paper mu is a sufficiently small constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Constraints (OCT-H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m_h.addVars(p,TB, vtype=GRB.BINARY, name=\"a_t\") #dim |TB|xp\n",
    "a_hat = m_h.addVars(p, TB, vtype=GRB.CONTINUOUS, lb=-1, ub=1, name=\"a_hat\")\n",
    "s = m_h.addVars(p,TB, vtype=GRB.BINARY, name=\"s\") #dim |TB|xp\n",
    "b = m_h.addVars(TB, vtype=GRB.CONTINUOUS, lb = 0, ub = 1, name=\"b_t\") #dim |TB| ###\n",
    "d = m_h.addVars(TB, vtype=GRB.BINARY, name=\"d_t\") #dim |TB|\n",
    "z = m_h.addVars(n, TL, vtype=GRB.BINARY, name=\"z\") #dim nx|TL|\n",
    "l = m_h.addVars(TL, vtype=GRB.BINARY, name=\"l_t\") #dim |TL|\n",
    "Nk = m_h.addVars(K, TL, vtype=GRB.INTEGER,name=\"N_kt\") #dim Kx|TL|\n",
    "N = m_h.addVars(TL, vtype=GRB.INTEGER, name=\"N_t\") #dim |TL|\n",
    "ck = m_h.addVars(K, TL, vtype=GRB.BINARY, name=\"c_kt\")\n",
    "L = m_h.addVars(TL, name=\"L_t\") \n",
    "\n",
    "for t in TB:\n",
    "    m_h.addConstr(gp.quicksum(a[i,t] for i in range(p)) == d[t], name=\"sum_constraint_of_ajt\") # sum of ajt = dt\n",
    "    m_h.addConstr(b[t] <= d[t], name=\"bt_constraint1_dt\")     # bt <= dt\n",
    "    m_h.addConstr(-d[t] <= b[t], name=\"bt_constraint2_dt\")    #-dt <= bt\n",
    "\n",
    "for t in TB[1:]:\n",
    "    m_h.addConstr(d[t] <= d[t//2], name=\"dt_constraint_dp(t)\") # dt <= dp(t)   \n",
    "\n",
    "for t in TB:\n",
    "    m_h.addConstr(gp.quicksum(s[i,t] for i in range(p)) >= d[t], name=\"sum_constraint_of_sjt\") \n",
    "    for i in range(p):\n",
    "        m_h.addConstr(s[i,t] <= d[t], name=\"s_constraint1_dt\")     # sjt <= dt\n",
    "        m_h.addConstr(-s[i,t] <= a[i,t], name=\"a_constraint1_-st\")  # -sjt <= ajt\n",
    "        m_h.addConstr(a[i,t] <= s[i,t], name=\"a_constraint2_st\")   # ajt <= sjt  \n",
    "\n",
    "for t in TB:\n",
    "    m_h.addConstr(gp.quicksum(a_hat[i,t] for i in range(p)) <= d[t], name=\"sum_constraint_of_a_hat\")\n",
    "    for i in range(p):\n",
    "        m_h.addConstr(a_hat[i,t] >= -a[i,t], name=\"a_hat_constraint_-a\") #a_hat >= -ajt \n",
    "        m_h.addConstr(a_hat[i,t] >= a[i,t], name=\"a_hat_constraint_a\")   #a_hat >= ajt  \n",
    "\n",
    "for t in TL:\n",
    "    for i in range(n):\n",
    "        m_h.addConstr(z[i, t] <= l[t]) # zit <= lt\n",
    "\n",
    "for t in TL:\n",
    "    m_h.addConstr(gp.quicksum(z[i,t] for i in range(n)) >= N_min*l[t], name=\"sum_of_zt_constraint_Nmin_lt\") # sum of zit >= Nmin*lt\n",
    "    \n",
    "for i in range(n):\n",
    "    m_h.addConstr(gp.quicksum(z[i,t] for t in TL) == 1, name=\"sum_of_zi(t)_constraint_1\")  # sum sum of zit = 1\n",
    "  \n",
    "for t in TL:\n",
    "    for k in range(K):\n",
    "        m_h.addConstr(Nk[k,t] == 1/2 * gp.quicksum(z[i,t] * (Y[i,k] + 1) for i in range(n))) #Nkt = 1/2(sum of (1+Yik)*zit \n",
    "         \n",
    "for t in TL:\n",
    "    m_h.addConstr(N[t] == gp.quicksum(z[i, t] for i in range(n)))  # Nt = sum of zit\n",
    "\n",
    "for t in TL:\n",
    "    m_h.addConstr(l[t] == gp.quicksum(ck[k, t] for k in range(K))) # sum of ckt = lt\n",
    "\n",
    "for t in TL:\n",
    "    if len(left_ancestors[t-1]) != 0:\n",
    "        for la in left_ancestors[t-1]:\n",
    "            for i in range(n):\n",
    "                axe = sum([(a[j,la])*(X.iloc[i].tolist()[j] + mu) for j in range(p)])\n",
    "                m_h.addConstr(axe <= b[la] + (2 + mu) * (1 - z[i,t]), name=\"split_structure_constraint_A_L\")\n",
    "                \n",
    "    if len(right_ancestors[t-1]) != 0:\n",
    "        for r in right_ancestors[t-1]:\n",
    "            for i in range(n):\n",
    "                ade = sum([(a[j,r])*(X.iloc[i].tolist()[j]) for j in range(p)])\n",
    "                m_h.addConstr(ade >= b[r] - 2*(1 - z[i,t]), name=\"split_structure_constraint_A_R\")\n",
    " \n",
    "for t in TL:\n",
    "    for k in range(K):\n",
    "        m_h.addConstr(L[t] >= N[t] - Nk[k,t] - n*(1-ck[k,t]), name=\"Lt_constraint1\") #Lt ≤ Nt − Nkt + n(1-ckt) \n",
    "        m_h.addConstr(L[t] <= N[t] - Nk[k,t] + n*ck[k,t], name=\"Lt_constraint2\")  #Lt ≤ Nt − Nkt + n*ckt \n",
    "    m_h.addConstr(L[t] >= 0, name=\"Lt_constraint3\") #Lt ≥ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective OCT-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_h.setObjective(gp.quicksum(L[t]/L_hat for t in TL) + alpha*gp.quicksum(gp.quicksum(s[i,t] for i in range(p)) for t in TB), GRB.MINIMIZE) #minimize L + alpha*sum(sum(sjt)) for j in p, t in TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) Ultra 9 185H, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 22 logical processors, using up to 22 threads\n",
      "\n",
      "Optimize a model with 126096 rows, 30697 columns and 1006646 nonzeros\n",
      "Model fingerprint: 0x8e8eff4f\n",
      "Variable types: 64 continuous, 30633 integer (30609 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-03, 4e+03]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+03]\n",
      "Found heuristic solution: objective 2848.7614679\n",
      "Presolve removed 177 rows and 57 columns\n",
      "Presolve time: 1.61s\n",
      "Presolved: 125919 rows, 30640 columns, 945306 nonzeros\n",
      "Variable types: 7 continuous, 30633 integer (30609 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal simplex, dual simplex, and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Root barrier log...\n",
      "\n",
      "Ordering time: 0.08s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 64\n",
      " AA' NZ     : 1.220e+06\n",
      " Factor NZ  : 3.928e+06 (roughly 100 MB of memory)\n",
      " Factor Ops : 1.347e+08 (less than 1 second per iteration)\n",
      " Threads    : 14\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   1.50384625e+04 -5.92396528e+05  3.72e+03 1.69e+01  7.51e+02     3s\n",
      "   1   2.34997331e+04 -4.90601425e+06  3.23e+03 1.81e+01  5.57e+02     3s\n",
      "   2   6.09473894e+03 -4.94868145e+06  3.70e+01 1.76e+00  3.48e+01     3s\n",
      "   3   4.79735402e+03 -2.62981104e+06  9.87e+00 8.48e-01  1.63e+01     3s\n",
      "   4   2.90921720e+03 -3.26106808e+05  3.31e+00 5.01e-02  1.92e+00     3s\n",
      "   5   9.77531762e+01 -5.09034522e+03  8.59e-02 2.57e-04  2.91e-02     4s\n",
      "   6   2.99378805e+01 -5.27604865e+02  2.46e-02 2.20e-05  3.12e-03     4s\n",
      "   7   9.91007131e+00 -2.65565280e+02  7.65e-03 8.51e-06  1.54e-03     4s\n",
      "   8   5.48736568e+00 -1.69568250e+02  3.97e-03 4.60e-06  9.78e-04     4s\n",
      "   9   9.57626605e-01 -3.78058985e+01  3.42e-04 2.88e-13  2.16e-04     4s\n",
      "  10   2.72472525e-01 -4.27245901e+00  8.82e-05 3.19e-13  2.51e-05     4s\n",
      "  11   1.35256823e-01 -2.39748106e-01  2.23e-05 5.48e-13  2.06e-06     4s\n",
      "  12   9.96023527e-04 -7.02758184e-03  2.34e-07 1.07e-10  4.39e-08     4s\n",
      "  13   6.46428722e-08 -3.49746990e-08  1.63e-11 3.26e-14  5.44e-13     4s\n",
      "  14   1.30547940e-13 -7.09602588e-14  2.42e-13 2.84e-14  1.10e-18     4s\n",
      "\n",
      "Barrier solved model in 14 iterations and 4.32 seconds (3.54 work units)\n",
      "Optimal objective 1.30547940e-13\n",
      "\n",
      "Concurrent spin time: 0.27s\n",
      "\n",
      "Solved with barrier\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 26701 iterations, 2.86 seconds (1.70 work units)\n",
      "Total elapsed time = 5.43s (DegenMoves)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0    8 2848.76147    0.00000   100%     -    5s\n",
      "H    0     0                     506.8348624    0.00000   100%     -    5s\n",
      "H    0     0                     487.6100917    0.00000   100%     -    6s\n",
      "H    0     0                     429.9357798    0.00000   100%     -    6s\n",
      "H    0     0                     394.9816514    0.00000   100%     -    6s\n",
      "     0     0    0.00000    0   28  394.98165    0.00000   100%     -    6s\n",
      "H    0     0                     386.2431193    0.00000   100%     -    7s\n",
      "H    0     0                     384.4954128    0.00000   100%     -    7s\n",
      "H    0     0                     381.0000000    0.00000   100%     -    7s\n",
      "H    0     0                     349.5412844    0.00000   100%     -    7s\n",
      "H    0     0                       0.0000000    0.00000  0.00%     -    8s\n",
      "     0     0    0.00000    0    4    0.00000    0.00000  0.00%     -    8s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 2\n",
      "  MIR: 15\n",
      "\n",
      "Explored 1 nodes (47984 simplex iterations) in 9.02 seconds (9.10 work units)\n",
      "Thread count was 22 (of 22 available processors)\n",
      "\n",
      "Solution count 10: 0 349.541 381 ... 2848.76\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "m_h.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
